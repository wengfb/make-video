#!/usr/bin/env python3
"""
GLMé›†æˆæµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯æ™ºè°±AI GLMé›†æˆæ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'scripts', '1_script_generator'))
from ai_client import AIClient


def test_glm_integration():
    """æµ‹è¯•GLMé›†æˆ"""

    print("=" * 60)
    print("GLMé›†æˆæµ‹è¯•")
    print("=" * 60)

    # æµ‹è¯•é…ç½®
    test_configs = [
        {
            'name': 'OpenAIå…¼å®¹æµ‹è¯•ï¼ˆæ¨¡æ‹ŸGLMï¼‰',
            'config': {
                'provider': 'glm',
                'model': 'glm-4',
                'api_key': 'test-key-will-fail',  # æµ‹è¯•ç”¨ï¼Œä¼šå¤±è´¥
                'base_url': 'https://open.bigmodel.cn/api/paas/v4/',
                'temperature': 0.7,
                'max_tokens': 100
            }
        }
    ]

    for test in test_configs:
        print(f"\nğŸ§ª æµ‹è¯•: {test['name']}")
        print("-" * 60)

        try:
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            client = AIClient(test['config'])
            print(f"âœ… AIClientåˆå§‹åŒ–æˆåŠŸ")
            print(f"   Provider: {client.provider}")
            print(f"   Model: {client.model}")
            print(f"   Base URL: {client.base_url}")

            # å°è¯•è°ƒç”¨ï¼ˆä¼šå› ä¸ºAPI keyæ— æ•ˆè€Œå¤±è´¥ï¼Œä½†å¯ä»¥éªŒè¯ä»£ç é€»è¾‘ï¼‰
            print(f"\nâš ï¸  å°è¯•APIè°ƒç”¨ï¼ˆé¢„æœŸä¼šå¤±è´¥ï¼Œå› ä¸ºAPI keyæ— æ•ˆï¼‰...")
            try:
                response = client.generate("æµ‹è¯•", "ä½ æ˜¯ä¸€ä¸ªæµ‹è¯•åŠ©æ‰‹")
                print(f"âœ… APIè°ƒç”¨æˆåŠŸ: {response[:50]}...")
            except Exception as e:
                error_msg = str(e)
                if "GLM API" in error_msg or "401" in error_msg or "è®¤è¯" in error_msg.lower():
                    print(f"âœ… APIè°ƒç”¨é€»è¾‘æ­£ç¡®ï¼ˆå¦‚é¢„æœŸå¤±è´¥ï¼‰")
                    print(f"   é”™è¯¯ä¿¡æ¯: {error_msg[:100]}...")
                else:
                    print(f"âŒ æœªé¢„æœŸçš„é”™è¯¯: {error_msg}")

        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")

    # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
    print("\n" + "=" * 60)
    print("ğŸ“‹ å¦‚ä½•é…ç½®GLMï¼š")
    print("=" * 60)
    print("""
1. è·å–GLM APIå¯†é’¥ï¼š
   è®¿é—® https://open.bigmodel.cn/
   æ³¨å†Œè´¦å·å¹¶åˆ›å»ºAPIå¯†é’¥

2. ç¼–è¾‘ config/settings.jsonï¼š
   {
     "ai": {
       "provider": "glm",
       "model": "glm-4",
       "api_key": "ä½ çš„GLM_APIå¯†é’¥",
       "base_url": "https://open.bigmodel.cn/api/paas/v4/",
       "temperature": 0.7,
       "max_tokens": 2000
     }
   }

3. å¯ç”¨çš„GLMæ¨¡å‹ï¼š
   - glm-4: é€šç”¨æ¨¡å‹ï¼ˆæ¨èï¼‰
   - glm-4-plus: å¢å¼ºç‰ˆ
   - glm-4-air: å¿«é€Ÿç‰ˆ
   - glm-4-flash: è¶…å¿«é€Ÿç‰ˆ

4. è¿è¡Œä¸»ç¨‹åºæµ‹è¯•ï¼š
   python main.py
   é€‰æ‹©èœå•1 â†’ ç”Ÿæˆä¸»é¢˜
""")

    print("=" * 60)
    print("âœ… GLMé›†æˆæµ‹è¯•å®Œæˆï¼")
    print("=" * 60)
    print("\nğŸ’¡ æç¤ºï¼š")
    print("   - ä»£ç é›†æˆå·²å®Œæˆï¼Œæ”¯æŒGLM provider")
    print("   - ä½¿ç”¨å‰éœ€é…ç½®æœ‰æ•ˆçš„GLM APIå¯†é’¥")
    print("   - GLMä½¿ç”¨OpenAIå…¼å®¹æ¥å£ï¼Œæ— éœ€é¢å¤–ä¾èµ–")
    print("   - æ‰€æœ‰æ¨¡å—ï¼ˆä¸»é¢˜ç”Ÿæˆã€è„šæœ¬ç”Ÿæˆï¼‰è‡ªåŠ¨æ”¯æŒGLM")
    print()


if __name__ == '__main__':
    test_glm_integration()
