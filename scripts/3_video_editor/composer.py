"""
è§†é¢‘åˆæˆå™¨
åŸºäºè„šæœ¬è‡ªåŠ¨åˆæˆå®Œæ•´è§†é¢‘
"""

import json
import os
import sys
from dataclasses import replace
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import tempfile
import shutil

# ä¿®å¤ç›¸å¯¹å¯¼å…¥é—®é¢˜ - å¯¼å…¥VideoEditor
sys.path.insert(0, os.path.dirname(__file__))
from editor import VideoEditor

# V5.6: å¯¼å…¥é¡¹ç›®å½’æ¡£å™¨
from project_archiver import ProjectArchiver

# å¯¼å…¥ç´ ææ¨èå™¨
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '2_material_manager'))
from recommender import MaterialRecommender
from manager import MaterialManager

from ffmpeg_renderer import (
    AudioPlan,
    FFmpegRenderError,
    FFmpegTimelineRenderer,
    SegmentSpec,
)


class VideoComposer:
    """è§†é¢‘åˆæˆå™¨ï¼ˆåŸºäºè„šæœ¬è‡ªåŠ¨ç”Ÿæˆè§†é¢‘ï¼‰"""

    def __init__(self, config_path: str = 'config/settings.json'):
        """
        åˆå§‹åŒ–è§†é¢‘åˆæˆå™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)

        self.editor = VideoEditor(config_path)
        self.material_manager = MaterialManager()  # ä½¿ç”¨é»˜è®¤å‚æ•°
        self.recommender = MaterialRecommender(self.material_manager, config_path)

        self.video_config = self.config.get('video', {})
        self.default_image_duration = self.video_config.get('default_image_duration', 5.0)
        self.default_transition_duration = self.video_config.get('transition_duration', 1.0)

    def compose_from_script(
        self,
        script: Dict[str, Any],
        auto_select_materials: bool = True,
        output_filename: Optional[str] = None,
        tts_metadata_path: Optional[str] = None,
        subtitle_file: Optional[str] = None,
        use_tts_audio: bool = True
    ) -> str:
        """
        æ ¹æ®è„šæœ¬è‡ªåŠ¨åˆæˆè§†é¢‘
        V5.6: æ–°å¢é¡¹ç›®å½’æ¡£åŠŸèƒ½ï¼Œå°†æ‰€æœ‰ç›¸å…³æ–‡ä»¶æ•´ç†åˆ°é¡¹ç›®æ–‡ä»¶å¤¹

        Args:
            script: è„šæœ¬å­—å…¸ï¼ˆåŒ…å«sectionsï¼‰
            auto_select_materials: æ˜¯å¦è‡ªåŠ¨é€‰æ‹©ç´ æ
            output_filename: è¾“å‡ºæ–‡ä»¶åï¼ˆå·²åºŸå¼ƒï¼Œä½¿ç”¨è„šæœ¬æ ‡é¢˜ï¼‰
            tts_metadata_path: TTSéŸ³é¢‘å…ƒæ•°æ®JSONæ–‡ä»¶è·¯å¾„ (V5.0æ–°å¢)
            subtitle_file: å­—å¹•æ–‡ä»¶è·¯å¾„(.srt/.ass) (V5.0æ–°å¢)
            use_tts_audio: æ˜¯å¦ä½¿ç”¨TTSéŸ³é¢‘æ›¿ä»£BGM (V5.0æ–°å¢)

        Returns:
            é¡¹ç›®æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆV5.6å˜æ›´ï¼šä¹‹å‰è¿”å›è§†é¢‘è·¯å¾„ï¼‰
        """
        print(f"\nğŸ¬ å¼€å§‹åˆæˆè§†é¢‘: {script.get('title', 'æœªå‘½å')}")
        print("=" * 60)

        sections = script.get('sections', [])
        if not sections:
            raise ValueError("è„šæœ¬æ²¡æœ‰ç« èŠ‚å†…å®¹")

        # V5.6: åˆ›å»ºé¡¹ç›®æ–‡ä»¶å¤¹å’Œå½’æ¡£å™¨
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        script_title = script.get('title', 'video')
        safe_title = "".join(c for c in script_title if c.isalnum() or c in (' ', '-', '_')).strip()
        project_name = f"{safe_title}_{timestamp}"
        project_folder = os.path.join('output/projects', project_name)

        archiver = ProjectArchiver(project_folder)
        archiver.create_project_structure()

        # ä¿å­˜è„šæœ¬å‰¯æœ¬
        archiver.save_script(script)

        # ğŸš€ å¤šçº¿ç¨‹ä¼˜åŒ–: å¹¶è¡Œå¤„ç†æ‰€æœ‰ç« èŠ‚
        print(f"\nğŸš€ ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç† {len(sections)} ä¸ªç« èŠ‚...")

        # V5.6: æ‰¹é‡æ¨èç´ æï¼ˆä¿å­˜å®Œæ•´æ¨èä¿¡æ¯ï¼‰
        section_materials = {}
        section_recommendations = {}  # æ–°å¢ï¼šä¿å­˜æ‰€æœ‰æ¨èï¼ˆç”¨äºæŠ¥å‘Šï¼‰

        if auto_select_materials:
            print("ğŸ” æ‰¹é‡æ¨èç´ æ...")
            with ThreadPoolExecutor(max_workers=min(8, len(sections))) as executor:
                future_to_section = {
                    executor.submit(self._recommend_material_for_section_v2, i, section): i
                    for i, section in enumerate(sections)
                }

                for future in as_completed(future_to_section):
                    section_idx = future_to_section[future]
                    try:
                        material_path, material_info, all_recommendations = future.result()
                        section_materials[section_idx] = (material_path, material_info)
                        section_recommendations[section_idx] = all_recommendations
                    except Exception as e:
                        print(f"   âš ï¸  ç« èŠ‚ {section_idx + 1} ç´ ææ¨èå¤±è´¥: {str(e)}")
                        section_materials[section_idx] = (None, None)
                        section_recommendations[section_idx] = []

        # å¹¶è¡Œåˆ›å»ºè§†é¢‘ç‰‡æ®µ
        print("ğŸ¬ å¹¶è¡Œåˆ›å»ºè§†é¢‘ç‰‡æ®µ...")
        # V5.6: è§†é¢‘è¾“å‡ºåˆ°ä¸´æ—¶è·¯å¾„
        temp_video_path = os.path.join(tempfile.gettempdir(), f"{project_name}.mp4")

        print(f"\nğŸ’¾ å¯¼å‡ºè§†é¢‘...")

        total_duration, segment_count = self._render_with_ffmpeg(
            sections=sections,
            section_materials=section_materials,
            output_path=temp_video_path,
            use_tts_audio=use_tts_audio,
            tts_metadata_path=tts_metadata_path,
            subtitle_file=subtitle_file,
        )

        print(f"\nâœ… è§†é¢‘åˆæˆå®Œæˆ")
        print(f"   æ—¶é•¿: {total_duration:.1f}ç§’")
        print(f"   ç‰‡æ®µæ•°: {segment_count}")

        # V5.6: å½’æ¡£æ‰€æœ‰ç›¸å…³æ–‡ä»¶
        print(f"\nğŸ“¦ å½’æ¡£é¡¹ç›®æ–‡ä»¶...")

        # å¤åˆ¶ç´ ææ–‡ä»¶
        archiver.copy_materials(section_materials, sections)

        # ç”Ÿæˆç´ æé€‰æ‹©æŠ¥å‘Š
        archiver.generate_selection_report(
            script,
            section_materials,
            section_recommendations
        )

        # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶
        if use_tts_audio and tts_metadata_path:
            archiver.copy_audio_files(tts_metadata_path)

        # å¤åˆ¶å­—å¹•æ–‡ä»¶
        if subtitle_file:
            archiver.copy_subtitle_file(subtitle_file)

        # ä¿å­˜åˆæˆæ—¥å¿—
        archiver.save_composition_log({
            'timestamp': timestamp,
            'duration': total_duration,
            'segments': segment_count,
            'use_tts_audio': use_tts_audio,
            'bgm_enabled': self.config.get('tts', {}).get('enable_bgm_mixing', True),
            'config': {
                'resolution': self.video_config.get('resolution'),
                'fps': self.video_config.get('fps'),
                'codec': self.video_config.get('codec'),
                'bitrate': self.video_config.get('bitrate')
            }
        })

        # ç§»åŠ¨è§†é¢‘åˆ°é¡¹ç›®æ–‡ä»¶å¤¹
        final_video_path = os.path.join(project_folder, 'video.mp4')
        shutil.move(temp_video_path, final_video_path)

        # ç”Ÿæˆé¡¹ç›®å…ƒæ•°æ®
        archiver.generate_metadata(
            script,
            {
                'duration': total_duration,
                'segments': segment_count,
                'resolution': self.video_config.get('resolution'),
                'fps': self.video_config.get('fps')
            }
        )

        print(f"\nğŸ‰ é¡¹ç›®å½’æ¡£å®Œæˆ!")
        print(f"   ğŸ“ é¡¹ç›®æ–‡ä»¶å¤¹: {project_folder}")
        print(f"   ğŸ¬ è§†é¢‘æ–‡ä»¶: {final_video_path}")
        print(f"\n   åŒ…å«æ–‡ä»¶:")
        print(f"      â€¢ video.mp4 - æœ€ç»ˆè§†é¢‘")
        print(f"      â€¢ script.json - è„šæœ¬æ–‡ä»¶")
        print(f"      â€¢ material_selection_report.json/txt - ç´ æé€‰æ‹©æŠ¥å‘Š")
        print(f"      â€¢ materials/ - ä½¿ç”¨çš„ç´ æå‰¯æœ¬")
        if use_tts_audio and tts_metadata_path:
            print(f"      â€¢ audio/ - TTSéŸ³é¢‘æ–‡ä»¶")
        if subtitle_file:
            print(f"      â€¢ subtitles.* - å­—å¹•æ–‡ä»¶")
        print(f"      â€¢ composition_log.txt - åˆæˆæ—¥å¿—")
        print(f"      â€¢ project_metadata.json - é¡¹ç›®å…ƒæ•°æ®")

        return project_folder

    def _build_segments(
        self,
        sections: List[Dict[str, Any]],
        section_materials: Dict[int, Tuple[Optional[str], Optional[Dict[str, Any]]]],
        tts_durations: Optional[List[float]] = None,
    ) -> List[SegmentSpec]:
        """
        æ„å»ºè§†é¢‘ç‰‡æ®µåˆ—è¡¨

        Args:
            sections: è„šæœ¬ç« èŠ‚åˆ—è¡¨
            section_materials: ç« èŠ‚ç´ ææ˜ å°„
            tts_durations: TTSéŸ³é¢‘æ—¶é•¿åˆ—è¡¨ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼Œå¦‚æœæä¾›ï¼‰

        Returns:
            è§†é¢‘ç‰‡æ®µåˆ—è¡¨
        """
        segments: List[SegmentSpec] = []
        text_enabled = self.video_config.get('show_narration_text', True)
        text_style = self._get_text_style()

        # V5.4: æ˜¯å¦ä½¿ç”¨TTSæ—¶é•¿ï¼ˆé…ç½®é¡¹ï¼‰
        use_tts_duration = self.video_config.get('use_tts_duration', True)

        for idx, section in enumerate(sections):
            section_name = section.get('section_name', f'ç« èŠ‚{idx + 1}')
            narration = section.get('narration', '')

            # V5.4: ä¼˜å…ˆä½¿ç”¨TTSå®é™…æ—¶é•¿ï¼Œç¡®ä¿éŸ³ç”»åŒæ­¥
            if use_tts_duration and tts_durations and idx < len(tts_durations):
                duration = tts_durations[idx]
                print(f"   ğŸ™ï¸  ç« èŠ‚ {idx + 1} ä½¿ç”¨TTSæ—¶é•¿: {duration:.2f}ç§’")
            else:
                duration = self._parse_duration(
                    section.get('duration', self.default_image_duration),
                    default=self.default_image_duration
                )

            material_path = None
            material_info = None
            if idx in section_materials:
                material_path, material_info = section_materials[idx]

            if not material_path:
                fallback_path = section.get('material_path') or section.get('material')
                if fallback_path and os.path.exists(fallback_path):
                    material_path = fallback_path

            source_type = self._detect_media_type(material_path)

            text_value = narration if text_enabled and narration else None
            segment = SegmentSpec(
                index=idx,
                source_path=material_path,
                source_type=source_type,
                duration=duration,
                text=text_value,
                section_name=section_name,
                text_style=text_style if text_value else None,
            )
            segments.append(segment)

            material_desc = 'é»‘å±' if source_type == 'color' else os.path.basename(material_path)
            print(f"   âœ… ç« èŠ‚ {idx + 1}/{len(sections)}: {section_name} (ç´ æ: {material_desc})")

        return segments

    def _detect_media_type(self, path: Optional[str]) -> str:
        if not path or not os.path.exists(path):
            return 'color'

        ext = os.path.splitext(path)[1].lower()
        if ext in {'.mp4', '.mov', '.mkv', '.avi', '.webm'}:
            return 'video'
        if ext in {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'}:
            return 'image'
        return 'color'

    def _get_text_style(self) -> Dict[str, str]:
        style: Dict[str, str] = {}
        subtitle_cfg = self.config.get('subtitle', {})
        font_path = subtitle_cfg.get('font')
        if font_path and os.path.exists(font_path):
            style['font'] = font_path
        style['fontsize'] = str(self.video_config.get('text_size', 40))
        style['fontcolor'] = subtitle_cfg.get('font_color', 'white')
        style['boxcolor'] = f"{subtitle_cfg.get('bg_color', 'black')}@{subtitle_cfg.get('bg_opacity', 0.5)}"
        style['boxborder'] = '30'
        style['margin'] = '100'
        return style

    def _build_audio_plan(
        self,
        *,
        use_tts_audio: bool,
        tts_metadata_path: Optional[str],
        video_duration: float,
    ) -> Optional[AudioPlan]:
        audio_codec = self.video_config.get('audio_codec', 'aac')
        bgm_path = self.video_config.get('default_bgm')
        bgm_volume = self.config.get('tts', {}).get('bgm_volume', 0.2)
        enable_bgm_mix = self.config.get('tts', {}).get('enable_bgm_mixing', True)

        if use_tts_audio and tts_metadata_path and os.path.exists(tts_metadata_path):
            print("ğŸ™ï¸  ä½¿ç”¨TTSéŸ³é¢‘...")
            try:
                with open(tts_metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
            except (OSError, json.JSONDecodeError) as exc:
                print(f"   âš ï¸  æ— æ³•è¯»å–TTSå…ƒæ•°æ®: {exc}")
            else:
                audio_items = metadata.get('audio_files', [])
                audio_files = [item.get('file_path') for item in audio_items if item.get('file_path') and os.path.exists(item.get('file_path'))]
                durations = [float(item.get('duration', 0.0) or 0.0) for item in audio_items if item.get('file_path') and os.path.exists(item.get('file_path'))]

                if audio_files:
                    print(f"   âœ… åˆå¹¶ {len(audio_files)} æ®µè¯­éŸ³")
                    bgm_candidate = bgm_path if (bgm_path and os.path.exists(bgm_path) and enable_bgm_mix) else None
                    target_duration = sum(durations) if durations else video_duration
                    return AudioPlan(
                        use_tts=True,
                        tts_inputs=audio_files,
                        tts_durations=durations or [target_duration],
                        bgm_path=bgm_candidate,
                        bgm_volume=bgm_volume,
                        target_duration=target_duration,
                        audio_codec=audio_codec,
                    )

        if bgm_path and os.path.exists(bgm_path):
            print("ğŸµ ä½¿ç”¨èƒŒæ™¯éŸ³ä¹å¡«å……éŸ³è½¨")
            return AudioPlan(
                use_tts=False,
                tts_inputs=[],
                tts_durations=[],
                bgm_path=bgm_path,
                bgm_volume=bgm_volume,
                target_duration=video_duration,
                audio_codec=audio_codec,
            )

        print("ğŸ”‡ æœªé…ç½®éŸ³é¢‘ï¼Œå°†è¾“å‡ºæ— å£°è§†é¢‘")
        return None

    def _get_resolution(self) -> Tuple[int, int]:
        resolution = self.video_config.get('resolution', {'width': 1920, 'height': 1080})
        if isinstance(resolution, dict):
            width = int(resolution.get('width', 1920))
            height = int(resolution.get('height', 1080))
        else:
            width, height = resolution
        return width, height

    def _render_with_ffmpeg(
        self,
        *,
        sections: List[Dict[str, Any]],
        section_materials: Dict[int, Tuple[Optional[str], Optional[Dict[str, Any]]]],
        output_path: str,
        use_tts_audio: bool,
        tts_metadata_path: Optional[str],
        subtitle_file: Optional[str] = None,
    ) -> Tuple[float, int]:
        # V5.4: æå–TTSæ—¶é•¿åˆ—è¡¨ï¼ˆå¦‚æœæœ‰ï¼‰
        tts_durations = None
        if use_tts_audio and tts_metadata_path and os.path.exists(tts_metadata_path):
            try:
                with open(tts_metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                audio_items = metadata.get('audio_files', [])
                tts_durations = [
                    float(item.get('duration', 0.0) or 0.0)
                    for item in audio_items
                    if item.get('file_path') and os.path.exists(item.get('file_path'))
                ]
                if tts_durations:
                    print(f"   ğŸ“Š å·²åŠ è½½ {len(tts_durations)} æ®µTTSæ—¶é•¿æ•°æ®")
            except (OSError, json.JSONDecodeError) as exc:
                print(f"   âš ï¸  æ— æ³•è¯»å–TTSå…ƒæ•°æ®: {exc}")
                tts_durations = None

        # æ„å»ºè§†é¢‘ç‰‡æ®µï¼ˆä½¿ç”¨TTSæ—¶é•¿ï¼‰
        segments = self._build_segments(
            sections=sections,
            section_materials=section_materials,
            tts_durations=tts_durations,
        )

        if not segments:
            raise ValueError("æ²¡æœ‰ç”Ÿæˆä»»ä½•è§†é¢‘ç‰‡æ®µ")

        total_duration = sum(segment.duration for segment in segments)
        audio_plan = self._build_audio_plan(
            use_tts_audio=use_tts_audio,
            tts_metadata_path=tts_metadata_path,
            video_duration=total_duration,
        )

        # V5.4: ç”±äºå·²ç»ä½¿ç”¨TTSæ—¶é•¿æ„å»ºç‰‡æ®µï¼Œä¸å†éœ€è¦è°ƒæ•´æœ€åä¸€ä¸ªç‰‡æ®µ
        # åªåœ¨æç«¯æƒ…å†µä¸‹ï¼ˆè¯¯å·®>1ç§’ï¼‰æ‰è°ƒæ•´
        if audio_plan and audio_plan.use_tts:
            audio_total = sum(audio_plan.tts_durations)
            diff = audio_total - total_duration
            if abs(diff) > 1.0:  # ä»0.1æ”¹ä¸º1.0ï¼Œåªåœ¨æœ‰æ˜æ˜¾è¯¯å·®æ—¶æ‰è°ƒæ•´
                print(f"   âš ï¸  è§†é¢‘æ€»æ—¶é•¿ä¸éŸ³é¢‘ä¸åŒ¹é…ï¼ˆå·®å¼‚ {diff:.2f}ç§’ï¼‰ï¼Œè°ƒæ•´æœ€åç‰‡æ®µ")
                last_segment = segments[-1]
                adjusted_duration = max(0.5, last_segment.duration + diff)
                segments[-1] = replace(last_segment, duration=adjusted_duration)

        total_duration = sum(segment.duration for segment in segments)
        if audio_plan:
            if audio_plan.use_tts:
                audio_total = sum(audio_plan.tts_durations)
                audio_plan.target_duration = max(audio_total, total_duration)
            else:
                audio_plan.target_duration = total_duration

        renderer = FFmpegTimelineRenderer(
            ffmpeg_path=os.environ.get('IMAGEIO_FFMPEG_EXE', 'ffmpeg'),
            ffprobe_path=os.environ.get('FFPROBE_BINARY', 'ffprobe'),
        )

        codec = self.video_config.get('codec', 'libx264')
        use_gpu = self.video_config.get('gpu_acceleration', False) and 'nvenc' in codec

        preset = None
        nvenc_params = None
        if use_gpu:
            preset = self.video_config.get('gpu_preset', 'p4')
            custom_nvenc = self.video_config.get('nvenc_params')
            if isinstance(custom_nvenc, list) and custom_nvenc:
                nvenc_params = [str(p) for p in custom_nvenc]
            else:
                cq = str(self.video_config.get('nvenc_cq', 19))
                nvenc_params = ['-rc', 'vbr', '-cq', cq]
            print(f"   ğŸš€ å¯ç”¨GPUåŠ é€Ÿ: {codec} (preset: {preset})")
        else:
            preset = self.video_config.get('preset', 'medium')

        # æ„å»ºå­—å¹•æ ·å¼é…ç½®
        subtitle_style = None
        if subtitle_file and os.path.exists(subtitle_file):
            subtitle_cfg = self.config.get('subtitle', {})
            subtitle_style = {
                'fontsize': str(subtitle_cfg.get('font_size', 48)),
                'fontcolor': subtitle_cfg.get('font_color', 'white'),
                'bg_color': subtitle_cfg.get('bg_color', 'black'),
                'bg_opacity': str(subtitle_cfg.get('bg_opacity', 0.5)),
            }
            print(f"   ğŸ“ ä½¿ç”¨å­—å¹•æ–‡ä»¶: {os.path.basename(subtitle_file)}")

        render_kwargs = dict(
            segments=segments,
            output_path=output_path,
            fps=self.video_config.get('fps', 24),
            resolution=self._get_resolution(),
            codec=codec,
            preset=preset,
            bitrate=self.video_config.get('bitrate'),
            threads=self.video_config.get('threads'),
            nvenc_params=nvenc_params,
            audio_plan=audio_plan,
            subtitle_file=subtitle_file,
            subtitle_style=subtitle_style,
        )

        try:
            renderer.render(**render_kwargs)
        except FFmpegRenderError as exc:
            if use_gpu:
                print("\nâš ï¸  NVENCå¯¼å‡ºå¤±è´¥ï¼Œå°è¯•å›é€€åˆ°CPUç¼–ç (libx264)...")
                print(f"   âŒ NVENCå¤±è´¥è¯¦æƒ…: {exc}")
                if os.path.exists(output_path):
                    try:
                        os.remove(output_path)
                    except OSError:
                        pass

                render_kwargs.update(
                    codec='libx264',
                    preset=self.video_config.get('preset', 'medium'),
                    nvenc_params=None,
                )
                renderer.render(**render_kwargs)
            else:
                raise

        return total_duration, len(segments)

    def compose_with_custom_materials(
        self,
        script: Dict[str, Any],
        material_mapping: Dict[int, str],
        output_filename: Optional[str] = None
    ) -> str:
        """
        ä½¿ç”¨è‡ªå®šä¹‰ç´ ææ˜ å°„åˆæˆè§†é¢‘

        Args:
            script: è„šæœ¬å­—å…¸
            material_mapping: ç« èŠ‚ç´¢å¼• -> ç´ æè·¯å¾„çš„æ˜ å°„
            output_filename: è¾“å‡ºæ–‡ä»¶å

        Returns:
            è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        print(f"\nğŸ¬ å¼€å§‹åˆæˆè§†é¢‘ï¼ˆè‡ªå®šä¹‰ç´ æï¼‰: {script.get('title', 'æœªå‘½å')}")

        sections = script.get('sections', [])
        if output_filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_filename = f"video_custom_{timestamp}.mp4"

        output_path = os.path.join(self.editor.output_dir, output_filename)
        section_materials = {
            idx: (path if path and os.path.exists(path) else None, None)
            for idx, path in material_mapping.items()
        }

        total_duration, segment_count = self._render_with_ffmpeg(
            sections=sections,
            section_materials=section_materials,
            output_path=output_path,
            use_tts_audio=False,
            tts_metadata_path=None,
        )

        print(f"\nâœ… è§†é¢‘åˆæˆå®Œæˆ: {output_path}")
        print(f"   æ—¶é•¿: {total_duration:.1f}ç§’")
        print(f"   ç‰‡æ®µæ•°: {segment_count}")

        return output_path

    def preview_material_recommendations(self, script: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        é¢„è§ˆè„šæœ¬å„ç« èŠ‚çš„ç´ ææ¨è
        V5.6: æ”¯æŒvisual_optionså¤šå±‚æ¬¡åœºæ™¯å±•ç¤º

        Args:
            script: è„šæœ¬å­—å…¸

        Returns:
            æ¨èåˆ—è¡¨ï¼ˆæ¯ä¸ªç« èŠ‚çš„æ¨èç´ æï¼‰
        """
        sections = script.get('sections', [])
        all_recommendations = []

        print(f"\nğŸ” ç´ ææ¨èé¢„è§ˆ: {script.get('title', 'æœªå‘½å')}")
        print("=" * 80)

        for i, section in enumerate(sections, 1):
            section_name = section.get('section_name', f'ç« èŠ‚{i}')
            narration = section.get('narration', '')[:60]

            print(f"\nğŸ“Œ {i}. {section_name}")
            print(f"   æ—ç™½: {narration}...")

            # V5.6: æ˜¾ç¤ºvisual_optionsï¼ˆå¦‚æœæœ‰ï¼‰
            visual_options = section.get('visual_options', [])
            if visual_options:
                print(f"\n   ğŸ¬ è§†è§‰æ–¹æ¡ˆï¼ˆ3ä¸ªå±‚æ¬¡ï¼‰:")
                for opt in visual_options:
                    priority = opt.get('priority', 0)
                    desc = opt.get('description', '')
                    complexity = opt.get('complexity', 'unknown')
                    source = opt.get('suggested_source', '')

                    # ä¼˜å…ˆçº§emoji
                    priority_emoji = {1: "ğŸŒŸ", 2: "â­", 3: "âœ¨"}.get(priority, "â€¢")

                    print(f"      {priority_emoji} Priority {priority} ({complexity})")
                    print(f"         {desc}")
                    print(f"         å»ºè®®æ¥æº: {source}")
            else:
                # æ˜¾ç¤ºæ—§æ ¼å¼çš„visual_notes
                visual_notes = section.get('visual_notes', '')
                if visual_notes:
                    print(f"   è§†è§‰: {visual_notes[:80]}...")

            print()  # ç©ºè¡Œ

            # è·å–æ¨èç´ æ
            recommendations = self.recommender.recommend_for_script_section(
                section,
                limit=5
            )

            if recommendations:
                # V5.6: å¢å¼ºæ˜¾ç¤ºæ ¼å¼
                best_rec = recommendations[0]
                matched_priority = best_rec.get('matched_priority', 0)
                semantic_score = best_rec.get('match_score', 0)

                # è¯„åˆ†ç­‰çº§
                if semantic_score >= 80:
                    score_level = "ä¼˜ç§€"
                    score_color = "âœ…"
                elif semantic_score >= 60:
                    score_level = "è‰¯å¥½"
                    score_color = "âš ï¸ "
                else:
                    score_level = "ä¸€èˆ¬"
                    score_color = "âŒ"

                print(f"   ğŸ¯ æ™ºèƒ½åŒ¹é…ç»“æœ:")
                if matched_priority:
                    print(f"      âœ… é‡‡ç”¨ Priority {matched_priority} æ–¹æ¡ˆ")
                print(f"      {score_color} è¯­ä¹‰åŒ¹é…åº¦: {semantic_score:.0f}% ({score_level})")

                # åŒ¹é…/ç¼ºå¤±å…ƒç´ 
                matched_elements = best_rec.get('matched_elements', [])
                missing_elements = best_rec.get('missing_elements', [])
                if matched_elements:
                    print(f"      âœ… åŒ¹é…å…ƒç´ : {', '.join(matched_elements)}")
                if missing_elements:
                    print(f"      âŒ ç¼ºå¤±å…ƒç´ : {', '.join(missing_elements)}")

                print(f"\n   ğŸ’ æ¨èç´ æ:")
                for j, rec in enumerate(recommendations, 1):
                    marker = "â­" if j == 1 else "  "
                    type_icon = "ğŸ¥" if rec['type'] == 'video' else "ğŸ–¼ï¸"
                    print(f"   {marker} {j}) {type_icon} {rec['name']}")

                    # åŒ¹é…ä¿¡æ¯
                    rec_score = rec.get('match_score', 0)
                    rec_priority = rec.get('matched_priority')
                    print(f"      ğŸ“Š åŒ¹é…åº¦: {rec_score:.0f}%", end="")
                    if rec_priority:
                        print(f" | Priority {rec_priority}", end="")
                    print(f" | ç±»å‹: {rec['type']}")

                    # æ ‡ç­¾
                    tags = rec.get('tags', [])[:3]
                    if tags:
                        print(f"      ğŸ·ï¸  æ ‡ç­¾: {', '.join(tags)}")

                    # AIåˆ†æåŸå› 
                    match_reason = rec.get('match_reason', '')
                    if match_reason:
                        print(f"      ğŸ’¡ AIåˆ†æ: {match_reason[:80]}...")

                    # æ–‡ä»¶è·¯å¾„
                    file_path = rec.get('file_path', '')
                    if file_path:
                        file_name = os.path.basename(file_path)
                        print(f"      ğŸ“ æ–‡ä»¶: {file_name}")

                    if j < len(recommendations):
                        print()  # ç´ æé—´ç©ºè¡Œ
            else:
                print("   âš ï¸  æœªæ‰¾åˆ°åˆé€‚ç´ æ")
                print("   ğŸ’¡ å»ºè®®: ä½¿ç”¨AIç”Ÿæˆæˆ–æ‰‹åŠ¨ä¸Šä¼ ç´ æ")

            all_recommendations.append({
                'section_index': i - 1,
                'section_name': section_name,
                'recommendations': recommendations
            })

        print("\n" + "=" * 80)
        print(f"ğŸ’¡ æç¤º: â­æ ‡è®°çš„ç´ æå°†è¢«è‡ªåŠ¨é€‰æ‹©ç”¨äºè§†é¢‘åˆæˆ")
        print(f"ğŸ“‹ æ“ä½œé€‰é¡¹:")
        print(f"   [1] ä½¿ç”¨æ¨èç´ æç›´æ¥åˆæˆ")
        print(f"   [2] æŸ¥çœ‹å•ä¸ªç« èŠ‚è¯¦æƒ…")
        print(f"   [3] æ‰‹åŠ¨é€‰æ‹©ç´ æ")

        return all_recommendations

    def _create_color_clip(self, color: Tuple[int, int, int], duration: float):
        """åˆ›å»ºçº¯è‰²å‰ªè¾‘"""
        from moviepy import ColorClip

        # å…¼å®¹å­—å…¸å’Œåˆ—è¡¨ä¸¤ç§resolutionæ ¼å¼
        resolution = self.video_config.get('resolution', {'width': 1920, 'height': 1080})
        if isinstance(resolution, dict):
            size = (resolution.get('width', 1920), resolution.get('height', 1080))
        else:
            size = resolution  # å‘åå…¼å®¹åˆ—è¡¨æ ¼å¼
        return ColorClip(size=size, color=color, duration=duration)

    def _create_text_clip(
        self,
        text: str,
        duration: float,
        position: Tuple = ('center', 'bottom'),
        fontsize: int = 40,
        color: str = 'white',
        bg_color: str = 'black'
    ):
        """åˆ›å»ºæ–‡å­—å‰ªè¾‘"""
        from moviepy import TextClip

        # æ–‡å­—æ¢è¡Œå¤„ç†
        max_chars_per_line = 30
        words = text.split()
        lines = []
        current_line = ""

        for word in words:
            if len(current_line + word) <= max_chars_per_line:
                current_line += word + " "
            else:
                if current_line:
                    lines.append(current_line.strip())
                current_line = word + " "

        if current_line:
            lines.append(current_line.strip())

        formatted_text = "\n".join(lines[:3])  # æœ€å¤š3è¡Œ

        # å…¼å®¹å­—å…¸å’Œåˆ—è¡¨ä¸¤ç§resolutionæ ¼å¼
        resolution = self.video_config.get('resolution', {'width': 1920, 'height': 1080})
        if isinstance(resolution, dict):
            width = resolution.get('width', 1920)
        else:
            width = resolution[0]  # å‘åå…¼å®¹åˆ—è¡¨æ ¼å¼

        txt_clip = TextClip(
            text=formatted_text,
            font_size=fontsize,
            color=color,
            bg_color=bg_color,
            method='caption',
            size=(width - 200, None)
        ).with_duration(duration).with_position(position)

        return txt_clip

    def get_composition_info(self, script: Dict[str, Any]) -> Dict[str, Any]:
        """
        è·å–åˆæˆä¿¡æ¯ï¼ˆä¸å®é™…åˆæˆï¼‰

        Args:
            script: è„šæœ¬å­—å…¸

        Returns:
            åˆæˆä¿¡æ¯å­—å…¸
        """
        sections = script.get('sections', [])

        total_duration = sum(
            self._parse_duration(s.get('duration', self.default_image_duration), self.default_image_duration)
            for s in sections
        )

        info = {
            'title': script.get('title', 'æœªå‘½å'),
            'total_sections': len(sections),
            'estimated_duration': total_duration,
            'estimated_file_size_mb': self._estimate_file_size(total_duration),
            'sections': []
        }

        for i, section in enumerate(sections, 1):
            section_info = {
                'index': i,
                'name': section.get('section_name', f'ç« èŠ‚{i}'),
                'duration': self._parse_duration(
                    section.get('duration', self.default_image_duration),
                    self.default_image_duration
                ),
                'has_narration': bool(section.get('narration')),
                'has_visual_notes': bool(section.get('visual_notes'))
            }
            info['sections'].append(section_info)

        return info

    def _estimate_file_size(self, duration: float) -> float:
        """ä¼°ç®—æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰"""
        # ç²—ç•¥ä¼°ç®—ï¼š1080p 24fps çº¦ 5MB/åˆ†é’Ÿ
        bitrate_mb_per_min = self.video_config.get('estimated_bitrate_mb_per_min', 5.0)
        return round((duration / 60.0) * bitrate_mb_per_min, 2)

    def _recommend_material_for_section(self, section_idx: int, section: Dict[str, Any]) -> Tuple[Optional[str], Optional[Dict]]:
        """
        ä¸ºå•ä¸ªç« èŠ‚æ¨èç´ æï¼ˆå¤šçº¿ç¨‹è¾…åŠ©å‡½æ•°ï¼‰

        Args:
            section_idx: ç« èŠ‚ç´¢å¼•
            section: ç« èŠ‚å­—å…¸

        Returns:
            (ç´ æè·¯å¾„, ç´ æä¿¡æ¯) å…ƒç»„
        """
        recommendations = self.recommender.recommend_for_script_section(section, limit=3)

        if recommendations:
            best_material = recommendations[0]
            return best_material['file_path'], best_material
        else:
            return None, None

    def _recommend_material_for_section_v2(self, section_idx: int, section: Dict[str, Any]) -> Tuple[Optional[str], Optional[Dict], List[Dict]]:
        """
        ä¸ºå•ä¸ªç« èŠ‚æ¨èç´ æï¼ˆV5.6å¢å¼ºç‰ˆ - è¿”å›å®Œæ•´æ¨èåˆ—è¡¨ç”¨äºå½’æ¡£ï¼‰

        Args:
            section_idx: ç« èŠ‚ç´¢å¼•
            section: ç« èŠ‚å­—å…¸

        Returns:
            (ç´ æè·¯å¾„, æœ€ä½³ç´ æä¿¡æ¯, æ‰€æœ‰æ¨èåˆ—è¡¨) å…ƒç»„
        """
        recommendations = self.recommender.recommend_for_script_section(section, limit=5)

        if recommendations:
            best_material = recommendations[0]
            return best_material['file_path'], best_material, recommendations
        else:
            return None, None, []

    def _create_clip_from_material(self, material_path: Optional[str], duration: float):
        """
        ä»ç´ æåˆ›å»ºè§†é¢‘ç‰‡æ®µï¼ˆå¤šçº¿ç¨‹è¾…åŠ©å‡½æ•°ï¼‰

        Args:
            material_path: ç´ æè·¯å¾„
            duration: æŒç»­æ—¶é—´

        Returns:
            è§†é¢‘ç‰‡æ®µå¯¹è±¡
        """
        from moviepy import ImageClip, VideoFileClip
        from moviepy.video.fx import Loop

        if material_path and os.path.exists(material_path):
            # æ ¹æ®ç´ æç±»å‹åˆ›å»ºå‰ªè¾‘
            ext = os.path.splitext(material_path)[1].lower()
            if ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']:
                clip = ImageClip(material_path).with_duration(duration)
            elif ext in ['.mp4', '.avi', '.mov', '.mkv']:
                video_clip = VideoFileClip(material_path)

                # ç§»é™¤éŸ³é¢‘ï¼ˆå› ä¸ºæˆ‘ä»¬ä¼šä½¿ç”¨TTSéŸ³é¢‘ï¼‰
                video_clip = video_clip.without_audio()

                # å¦‚æœè§†é¢‘é•¿åº¦ä¸å¤Ÿï¼Œå¾ªç¯æ’­æ”¾
                if video_clip.duration < duration:
                    clip = video_clip.with_effects([Loop(duration=duration)])
                else:
                    clip = video_clip.subclipped(0, duration)
            else:
                clip = self._create_color_clip((0, 0, 0), duration)
        else:
            # åˆ›å»ºé»‘å±
            clip = self._create_color_clip((0, 0, 0), duration)

        return self._ensure_target_resolution(clip)

    def _ensure_target_resolution(self, clip):
        """ç¡®ä¿å‰ªè¾‘ç¬¦åˆç›®æ ‡åˆ†è¾¨ç‡ï¼ˆLetterbox é€‚é…ï¼‰ã€‚"""
        try:
            resolution = self.video_config.get('resolution', {'width': 1920, 'height': 1080})
            if isinstance(resolution, dict):
                target_width = int(resolution.get('width', 1920))
                target_height = int(resolution.get('height', 1080))
            else:
                target_width, target_height = resolution

            if not target_width or not target_height:
                return clip

            clip_width, clip_height = clip.size
            if clip_width is None or clip_height is None:
                return clip

            # NVENC éœ€è¦å¶æ•°åˆ†è¾¨ç‡
            target_width = max(2, (target_width // 2) * 2)
            target_height = max(2, (target_height // 2) * 2)

            if clip_width == target_width and clip_height == target_height:
                return clip

            clip_ratio = clip_width / clip_height
            target_ratio = target_width / target_height

            if clip_ratio >= target_ratio:
                new_width = target_width
                new_height = int(round(target_width / clip_ratio))
            else:
                new_height = target_height
                new_width = int(round(target_height * clip_ratio))

            # ä¿è¯å¶æ•°å°ºå¯¸
            new_width = max(2, (new_width // 2) * 2)
            new_height = max(2, (new_height // 2) * 2)

            resized_clip = clip.resized(new_size=(new_width, new_height))

            return resized_clip.with_background_color(
                size=(target_width, target_height),
                color=(0, 0, 0),
                pos='center'
            )
        except Exception as e:
            print(f"   âš ï¸  è°ƒæ•´åˆ†è¾¨ç‡å¤±è´¥: {e}")
            return clip

    def _parse_duration(self, duration_value: Any, default: float = 5.0) -> float:
        """
        è§£ædurationå€¼ï¼Œæ”¯æŒå­—ç¬¦ä¸²å’Œæ•°å­—æ ¼å¼

        Args:
            duration_value: durationå€¼ï¼ˆå¯èƒ½æ˜¯"15ç§’"ã€"15s"ã€15ã€15.0ç­‰ï¼‰
            default: è§£æå¤±è´¥æ—¶çš„é»˜è®¤å€¼

        Returns:
            è§£æåçš„æµ®ç‚¹æ•°ç§’æ•°

        Examples:
            "15ç§’" -> 15.0
            "110ç§’" -> 110.0
            "15s" -> 15.0
            15 -> 15.0
            15.0 -> 15.0
        """
        import re

        # å¦‚æœå·²ç»æ˜¯æ•°å­—ï¼Œç›´æ¥è¿”å›
        if isinstance(duration_value, (int, float)):
            return float(duration_value)

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæå–æ•°å­—
        if isinstance(duration_value, str):
            # åŒ¹é…æ•°å­—ï¼ˆæ•´æ•°æˆ–å°æ•°ï¼‰
            match = re.search(r'(\d+\.?\d*)', duration_value)
            if match:
                try:
                    return float(match.group(1))
                except ValueError:
                    pass

        # è§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
        return default
