"""
è§†é¢‘åˆæˆå™¨
åŸºäºè„šæœ¬è‡ªåŠ¨åˆæˆå®Œæ•´è§†é¢‘
"""

import json
import os
import sys
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime

# ä¿®å¤ç›¸å¯¹å¯¼å…¥é—®é¢˜ - å¯¼å…¥VideoEditor
sys.path.insert(0, os.path.dirname(__file__))
from editor import VideoEditor

# å¯¼å…¥ç´ ææ¨èå™¨
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '2_material_manager'))
from recommender import MaterialRecommender
from manager import MaterialManager


class VideoComposer:
    """è§†é¢‘åˆæˆå™¨ï¼ˆåŸºäºè„šæœ¬è‡ªåŠ¨ç”Ÿæˆè§†é¢‘ï¼‰"""

    def __init__(self, config_path: str = 'config/settings.json'):
        """
        åˆå§‹åŒ–è§†é¢‘åˆæˆå™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)

        self.editor = VideoEditor(config_path)
        self.material_manager = MaterialManager()  # ä½¿ç”¨é»˜è®¤å‚æ•°
        self.recommender = MaterialRecommender(self.material_manager, config_path)

        self.video_config = self.config.get('video', {})
        self.default_image_duration = self.video_config.get('default_image_duration', 5.0)
        self.default_transition_duration = self.video_config.get('transition_duration', 1.0)

    def compose_from_script(
        self,
        script: Dict[str, Any],
        auto_select_materials: bool = True,
        output_filename: Optional[str] = None,
        tts_metadata_path: Optional[str] = None,
        subtitle_file: Optional[str] = None,
        use_tts_audio: bool = True
    ) -> str:
        """
        æ ¹æ®è„šæœ¬è‡ªåŠ¨åˆæˆè§†é¢‘ (V5.0 - æ”¯æŒTTSå’Œå­—å¹•)

        Args:
            script: è„šæœ¬å­—å…¸ï¼ˆåŒ…å«sectionsï¼‰
            auto_select_materials: æ˜¯å¦è‡ªåŠ¨é€‰æ‹©ç´ æ
            output_filename: è¾“å‡ºæ–‡ä»¶å
            tts_metadata_path: TTSéŸ³é¢‘å…ƒæ•°æ®JSONæ–‡ä»¶è·¯å¾„ (V5.0æ–°å¢)
            subtitle_file: å­—å¹•æ–‡ä»¶è·¯å¾„(.srt/.ass) (V5.0æ–°å¢)
            use_tts_audio: æ˜¯å¦ä½¿ç”¨TTSéŸ³é¢‘æ›¿ä»£BGM (V5.0æ–°å¢)

        Returns:
            è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        if not self.editor.moviepy_available:
            raise ImportError("moviepyæœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install moviepy")

        from moviepy import (
            ImageClip, VideoFileClip, TextClip, CompositeVideoClip,
            concatenate_videoclips, AudioFileClip
        )
        from moviepy.video.fx import Loop
        from moviepy.audio.fx import AudioLoop

        print(f"\nğŸ¬ å¼€å§‹åˆæˆè§†é¢‘: {script.get('title', 'æœªå‘½å')}")
        print("=" * 60)

        sections = script.get('sections', [])
        if not sections:
            raise ValueError("è„šæœ¬æ²¡æœ‰ç« èŠ‚å†…å®¹")

        # åˆå§‹åŒ–clipsåˆ—è¡¨(å¿…é¡»åœ¨tryå¤–éƒ¨,ç¡®ä¿finallyå¯ä»¥è®¿é—®)
        all_clips = []
        temp_clips = []  # ç”¨äºè·Ÿè¸ªéœ€è¦æ¸…ç†çš„ä¸´æ—¶clip
        audio_clips = []  # ç”¨äºè·Ÿè¸ªéŸ³é¢‘clips

        # éå†æ¯ä¸ªç« èŠ‚
        for i, section in enumerate(sections, 1):
            print(f"\nğŸ“ å¤„ç†ç« èŠ‚ {i}/{len(sections)}: {section.get('section_name', f'ç« èŠ‚{i}')}")

            # è·å–ç« èŠ‚ä¿¡æ¯
            narration = section.get('narration', '')
            visual_notes = section.get('visual_notes', '')
            duration = self._parse_duration(
                section.get('duration', self.default_image_duration),
                default=self.default_image_duration
            )

            # æ¨èç´ æ
            if auto_select_materials:
                print("   ğŸ” æ™ºèƒ½æ¨èç´ æ...")
                recommendations = self.recommender.recommend_for_script_section(
                    section,
                    limit=3
                )

                if recommendations:
                    best_material = recommendations[0]
                    material_path = best_material['file_path']
                    print(f"   âœ… é€‰æ‹©ç´ æ: {best_material['name']} (åŒ¹é…åº¦: {best_material['match_score']:.0f}%)")
                else:
                    print("   âš ï¸  æœªæ‰¾åˆ°åˆé€‚ç´ æï¼Œä½¿ç”¨é»˜è®¤é»‘å±")
                    material_path = None
            else:
                material_path = None

            # åˆ›å»ºè§†é¢‘ç‰‡æ®µ
            if material_path and os.path.exists(material_path):
                # æ ¹æ®ç´ æç±»å‹åˆ›å»ºå‰ªè¾‘
                ext = os.path.splitext(material_path)[1].lower()
                if ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']:
                    clip = ImageClip(material_path).with_duration(duration)
                elif ext in ['.mp4', '.avi', '.mov', '.mkv']:
                    video_clip = VideoFileClip(material_path)
                    # å¦‚æœè§†é¢‘é•¿åº¦ä¸å¤Ÿï¼Œå¾ªç¯æ’­æ”¾
                    if video_clip.duration < duration:
                        clip = video_clip.with_effects([Loop(duration=duration)])
                    else:
                        clip = video_clip.subclipped(0, duration)
                else:
                    print(f"   âš ï¸  ä¸æ”¯æŒçš„ç´ ææ ¼å¼: {ext}")
                    clip = self._create_color_clip((0, 0, 0), duration)
            else:
                # åˆ›å»ºé»‘å±
                clip = self._create_color_clip((0, 0, 0), duration)

            # æ·»åŠ æ–‡å­—ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if self.video_config.get('show_narration_text', True) and narration:
                text_clip = self._create_text_clip(
                    narration,
                    duration=duration,
                    position=('center', 'bottom'),
                    fontsize=self.video_config.get('text_size', 40)
                )
                clip = CompositeVideoClip([clip, text_clip])

            all_clips.append(clip)

        if not all_clips:
            raise ValueError("æ²¡æœ‰ç”Ÿæˆä»»ä½•è§†é¢‘ç‰‡æ®µ")

        # åˆå¹¶æ‰€æœ‰ç‰‡æ®µ
        print(f"\nğŸï¸  åˆå¹¶ {len(all_clips)} ä¸ªç‰‡æ®µ...")
        final_video = concatenate_videoclips(all_clips, method="compose")

        # V5.0: æ·»åŠ TTSè¯­éŸ³æˆ–èƒŒæ™¯éŸ³ä¹
        if use_tts_audio and tts_metadata_path and os.path.exists(tts_metadata_path):
            print("ğŸ™ï¸  æ·»åŠ TTSè¯­éŸ³...")
            try:
                # è¯»å–TTSå…ƒæ•°æ®
                with open(tts_metadata_path, 'r', encoding='utf-8') as f:
                    tts_metadata = json.load(f)

                audio_files = [item['file_path'] for item in tts_metadata.get('audio_files', [])]

                if audio_files:
                    # åˆå¹¶æ‰€æœ‰TTSéŸ³é¢‘
                    tts_audio_clips = [AudioFileClip(f) for f in audio_files if os.path.exists(f)]
                    audio_clips.extend(tts_audio_clips)  # è¿½è¸ªä»¥ä¾¿æ¸…ç†
                    if tts_audio_clips:
                        from moviepy import concatenate_audioclips
                        tts_audio = concatenate_audioclips(tts_audio_clips)

                        # æ·»åŠ BGMä½œä¸ºèƒŒæ™¯(é™ä½éŸ³é‡)
                        bgm_path = self.video_config.get('default_bgm')
                        if bgm_path and os.path.exists(bgm_path):
                            bgm = AudioFileClip(bgm_path)
                            if bgm.duration < tts_audio.duration:
                                bgm = bgm.with_effects([AudioLoop(duration=tts_audio.duration)])
                            else:
                                bgm = bgm.subclipped(0, tts_audio.duration)
                            # é™ä½BGMéŸ³é‡
                            bgm = bgm.with_volume_scaled(0.2)
                            # æ··åˆTTSå’ŒBGM
                            from moviepy.audio.AudioClip import CompositeAudioClip
                            final_audio = CompositeAudioClip([tts_audio, bgm])
                        else:
                            final_audio = tts_audio

                        final_video = final_video.with_audio(final_audio)
                        print(f"   âœ… TTSéŸ³é¢‘å·²æ·»åŠ  (æ—¶é•¿: {tts_audio.duration:.1f}ç§’)")

                        # è°ƒæ•´è§†é¢‘é•¿åº¦ä»¥åŒ¹é…éŸ³é¢‘
                        if final_video.duration != tts_audio.duration:
                            print(f"   âš ï¸  è°ƒæ•´è§†é¢‘é•¿åº¦: {final_video.duration:.1f}ç§’ -> {tts_audio.duration:.1f}ç§’")
                            final_video = final_video.with_duration(tts_audio.duration)
            except Exception as e:
                print(f"   âš ï¸  æ·»åŠ TTSéŸ³é¢‘å¤±è´¥: {str(e)}")
                import traceback
                traceback.print_exc()
        else:
            # æ·»åŠ èƒŒæ™¯éŸ³ä¹ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
            bgm_path = self.video_config.get('default_bgm')
            if bgm_path and os.path.exists(bgm_path):
                print("ğŸµ æ·»åŠ èƒŒæ™¯éŸ³ä¹...")
                try:
                    audio = AudioFileClip(bgm_path)
                    # å¾ªç¯èƒŒæ™¯éŸ³ä¹ä»¥åŒ¹é…è§†é¢‘é•¿åº¦
                    if audio.duration < final_video.duration:
                        audio = audio.with_effects([AudioLoop(duration=final_video.duration)])
                    else:
                        audio = audio.subclipped(0, final_video.duration)

                    final_video = final_video.with_audio(audio)
                except Exception as e:
                    print(f"   âš ï¸  æ·»åŠ éŸ³ä¹å¤±è´¥: {str(e)}")

        # V5.0: æ·»åŠ å­—å¹•
        if subtitle_file and os.path.exists(subtitle_file):
            print(f"ğŸ“ æ·»åŠ å­—å¹•: {subtitle_file}")
            try:
                from moviepy.video.tools.subtitles import SubtitlesClip

                # åˆ›å»ºå­—å¹•å‡½æ•°
                def generator(txt):
                    from moviepy import TextClip
                    return TextClip(
                        text=txt,
                        font_size=self.video_config.get('text_size', 48),
                        color='white',
                        bg_color='black',
                        method='caption',
                        size=(final_video.w - 200, None)
                    )

                # åŠ è½½å­—å¹•
                subtitles = SubtitlesClip(subtitle_file, generator)

                # åˆæˆè§†é¢‘å’Œå­—å¹•
                from moviepy import CompositeVideoClip
                final_video = CompositeVideoClip([
                    final_video,
                    subtitles.with_position(('center', 'bottom'))
                ])

                print("   âœ… å­—å¹•å·²æ·»åŠ ")
            except Exception as e:
                print(f"   âš ï¸  æ·»åŠ å­—å¹•å¤±è´¥: {str(e)}")
                print(f"   æç¤º: ç¡®ä¿å­—å¹•æ–‡ä»¶æ ¼å¼æ­£ç¡®,ä¸”moviepyæ”¯æŒå­—å¹•åŠŸèƒ½")
                import traceback
                traceback.print_exc()

        # è¾“å‡ºæ–‡ä»¶
        if output_filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            script_title = script.get('title', 'video')
            # æ¸…ç†æ–‡ä»¶å
            safe_title = "".join(c for c in script_title if c.isalnum() or c in (' ', '-', '_')).strip()
            output_filename = f"{safe_title}_{timestamp}.mp4"

        output_path = os.path.join(self.editor.output_dir, output_filename)

        print(f"\nğŸ’¾ å¯¼å‡ºè§†é¢‘...")
        try:
            final_video.write_videofile(
                output_path,
                fps=self.video_config.get('fps', 24),
                codec=self.video_config.get('codec', 'libx264'),
                audio_codec=self.video_config.get('audio_codec', 'aac')
            )

            print(f"\nâœ… è§†é¢‘åˆæˆå®Œæˆ: {output_path}")
            print(f"   æ—¶é•¿: {final_video.duration:.1f}ç§’")
            print(f"   ç‰‡æ®µæ•°: {len(all_clips)}")

            return output_path

        finally:
            # æ¸…ç†èµ„æº - é˜²æ­¢å†…å­˜æ³„æ¼
            print("\nğŸ§¹ æ¸…ç†ä¸´æ—¶èµ„æº...")
            try:
                # æ¸…ç†è§†é¢‘clips
                for clip in all_clips:
                    if clip and hasattr(clip, 'close'):
                        try:
                            clip.close()
                        except:
                            pass

                # æ¸…ç†éŸ³é¢‘clips
                for clip in audio_clips:
                    if clip and hasattr(clip, 'close'):
                        try:
                            clip.close()
                        except:
                            pass

                # æ¸…ç†æœ€ç»ˆè§†é¢‘
                if 'final_video' in locals() and hasattr(final_video, 'close'):
                    try:
                        final_video.close()
                    except:
                        pass
            except Exception as e:
                print(f"   âš ï¸  æ¸…ç†èµ„æºæ—¶å‡ºç°è­¦å‘Š: {str(e)}")

    def compose_with_custom_materials(
        self,
        script: Dict[str, Any],
        material_mapping: Dict[int, str],
        output_filename: Optional[str] = None
    ) -> str:
        """
        ä½¿ç”¨è‡ªå®šä¹‰ç´ ææ˜ å°„åˆæˆè§†é¢‘

        Args:
            script: è„šæœ¬å­—å…¸
            material_mapping: ç« èŠ‚ç´¢å¼• -> ç´ æè·¯å¾„çš„æ˜ å°„
            output_filename: è¾“å‡ºæ–‡ä»¶å

        Returns:
            è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        if not self.editor.moviepy_available:
            raise ImportError("moviepyæœªå®‰è£…")

        from moviepy import (
            ImageClip, VideoFileClip, TextClip, CompositeVideoClip,
            concatenate_videoclips
        )

        print(f"\nğŸ¬ å¼€å§‹åˆæˆè§†é¢‘ï¼ˆè‡ªå®šä¹‰ç´ æï¼‰: {script.get('title', 'æœªå‘½å')}")

        sections = script.get('sections', [])
        all_clips = []

        for i, section in enumerate(sections):
            material_path = material_mapping.get(i)

            if material_path and os.path.exists(material_path):
                duration = self._parse_duration(
                    section.get('duration', self.default_image_duration),
                    default=self.default_image_duration
                )

                ext = os.path.splitext(material_path)[1].lower()
                if ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']:
                    clip = ImageClip(material_path).with_duration(duration)
                elif ext in ['.mp4', '.avi', '.mov', '.mkv']:
                    video_clip = VideoFileClip(material_path)
                    if video_clip.duration < duration:
                        clip = video_clip.with_effects([Loop(duration=duration)])
                    else:
                        clip = video_clip.subclipped(0, duration)
                else:
                    continue

                # æ·»åŠ æ–‡å­—
                narration = section.get('narration', '')
                if narration and self.video_config.get('show_narration_text', True):
                    text_clip = self._create_text_clip(
                        narration,
                        duration=duration,
                        position=('center', 'bottom')
                    )
                    clip = CompositeVideoClip([clip, text_clip])

                all_clips.append(clip)

        if not all_clips:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„è§†é¢‘ç‰‡æ®µ")

        final_video = concatenate_videoclips(all_clips, method="compose")

        if output_filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_filename = f"video_custom_{timestamp}.mp4"

        output_path = os.path.join(self.editor.output_dir, output_filename)
        final_video.write_videofile(output_path, fps=24)

        print(f"\nâœ… è§†é¢‘åˆæˆå®Œæˆ: {output_path}")
        return output_path

    def preview_material_recommendations(self, script: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        é¢„è§ˆè„šæœ¬å„ç« èŠ‚çš„ç´ ææ¨è

        Args:
            script: è„šæœ¬å­—å…¸

        Returns:
            æ¨èåˆ—è¡¨ï¼ˆæ¯ä¸ªç« èŠ‚çš„æ¨èç´ æï¼‰
        """
        sections = script.get('sections', [])
        all_recommendations = []

        print(f"\nğŸ” ç´ ææ¨èé¢„è§ˆ: {script.get('title', 'æœªå‘½å')}")
        print("=" * 60)

        for i, section in enumerate(sections, 1):
            section_name = section.get('section_name', f'ç« èŠ‚{i}')
            print(f"\n{i}. {section_name}")

            recommendations = self.recommender.recommend_for_script_section(
                section,
                limit=5
            )

            if recommendations:
                for j, rec in enumerate(recommendations, 1):
                    print(f"   {j}) {rec['name']} (åŒ¹é…åº¦: {rec['match_score']:.0f}%)")
                    print(f"      ç±»å‹: {rec['type']} | æ ‡ç­¾: {', '.join(rec.get('tags', []))}")
                    print(f"      åŸå› : {rec.get('match_reason', 'N/A')}")
            else:
                print("   âš ï¸  æœªæ‰¾åˆ°åˆé€‚ç´ æ")

            all_recommendations.append({
                'section_index': i - 1,
                'section_name': section_name,
                'recommendations': recommendations
            })

        return all_recommendations

    def _create_color_clip(self, color: Tuple[int, int, int], duration: float):
        """åˆ›å»ºçº¯è‰²å‰ªè¾‘"""
        from moviepy import ColorClip

        # å…¼å®¹å­—å…¸å’Œåˆ—è¡¨ä¸¤ç§resolutionæ ¼å¼
        resolution = self.video_config.get('resolution', {'width': 1920, 'height': 1080})
        if isinstance(resolution, dict):
            size = (resolution.get('width', 1920), resolution.get('height', 1080))
        else:
            size = resolution  # å‘åå…¼å®¹åˆ—è¡¨æ ¼å¼
        return ColorClip(size=size, color=color, duration=duration)

    def _create_text_clip(
        self,
        text: str,
        duration: float,
        position: Tuple = ('center', 'bottom'),
        fontsize: int = 40,
        color: str = 'white',
        bg_color: str = 'black'
    ):
        """åˆ›å»ºæ–‡å­—å‰ªè¾‘"""
        from moviepy import TextClip

        # æ–‡å­—æ¢è¡Œå¤„ç†
        max_chars_per_line = 30
        words = text.split()
        lines = []
        current_line = ""

        for word in words:
            if len(current_line + word) <= max_chars_per_line:
                current_line += word + " "
            else:
                if current_line:
                    lines.append(current_line.strip())
                current_line = word + " "

        if current_line:
            lines.append(current_line.strip())

        formatted_text = "\n".join(lines[:3])  # æœ€å¤š3è¡Œ

        # å…¼å®¹å­—å…¸å’Œåˆ—è¡¨ä¸¤ç§resolutionæ ¼å¼
        resolution = self.video_config.get('resolution', {'width': 1920, 'height': 1080})
        if isinstance(resolution, dict):
            width = resolution.get('width', 1920)
        else:
            width = resolution[0]  # å‘åå…¼å®¹åˆ—è¡¨æ ¼å¼

        txt_clip = TextClip(
            text=formatted_text,
            font_size=fontsize,
            color=color,
            bg_color=bg_color,
            method='caption',
            size=(width - 200, None)
        ).with_duration(duration).with_position(position)

        return txt_clip

    def get_composition_info(self, script: Dict[str, Any]) -> Dict[str, Any]:
        """
        è·å–åˆæˆä¿¡æ¯ï¼ˆä¸å®é™…åˆæˆï¼‰

        Args:
            script: è„šæœ¬å­—å…¸

        Returns:
            åˆæˆä¿¡æ¯å­—å…¸
        """
        sections = script.get('sections', [])

        total_duration = sum(
            self._parse_duration(s.get('duration', self.default_image_duration), self.default_image_duration)
            for s in sections
        )

        info = {
            'title': script.get('title', 'æœªå‘½å'),
            'total_sections': len(sections),
            'estimated_duration': total_duration,
            'estimated_file_size_mb': self._estimate_file_size(total_duration),
            'sections': []
        }

        for i, section in enumerate(sections, 1):
            section_info = {
                'index': i,
                'name': section.get('section_name', f'ç« èŠ‚{i}'),
                'duration': self._parse_duration(
                    section.get('duration', self.default_image_duration),
                    self.default_image_duration
                ),
                'has_narration': bool(section.get('narration')),
                'has_visual_notes': bool(section.get('visual_notes'))
            }
            info['sections'].append(section_info)

        return info

    def _estimate_file_size(self, duration: float) -> float:
        """ä¼°ç®—æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰"""
        # ç²—ç•¥ä¼°ç®—ï¼š1080p 24fps çº¦ 5MB/åˆ†é’Ÿ
        bitrate_mb_per_min = self.video_config.get('estimated_bitrate_mb_per_min', 5.0)
        return round((duration / 60.0) * bitrate_mb_per_min, 2)

    def _parse_duration(self, duration_value: Any, default: float = 5.0) -> float:
        """
        è§£ædurationå€¼ï¼Œæ”¯æŒå­—ç¬¦ä¸²å’Œæ•°å­—æ ¼å¼

        Args:
            duration_value: durationå€¼ï¼ˆå¯èƒ½æ˜¯"15ç§’"ã€"15s"ã€15ã€15.0ç­‰ï¼‰
            default: è§£æå¤±è´¥æ—¶çš„é»˜è®¤å€¼

        Returns:
            è§£æåçš„æµ®ç‚¹æ•°ç§’æ•°

        Examples:
            "15ç§’" -> 15.0
            "110ç§’" -> 110.0
            "15s" -> 15.0
            15 -> 15.0
            15.0 -> 15.0
        """
        import re

        # å¦‚æœå·²ç»æ˜¯æ•°å­—ï¼Œç›´æ¥è¿”å›
        if isinstance(duration_value, (int, float)):
            return float(duration_value)

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæå–æ•°å­—
        if isinstance(duration_value, str):
            # åŒ¹é…æ•°å­—ï¼ˆæ•´æ•°æˆ–å°æ•°ï¼‰
            match = re.search(r'(\d+\.?\d*)', duration_value)
            if match:
                try:
                    return float(match.group(1))
                except ValueError:
                    pass

        # è§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
        return default
