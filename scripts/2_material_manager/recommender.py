"""
æ™ºèƒ½ç´ ææ¨èç³»ç»Ÿ
æ ¹æ®è„šæœ¬å†…å®¹æ™ºèƒ½æ¨èåˆé€‚çš„ç´ æ
V5.1 æ–°å¢: å››çº§æ™ºèƒ½è·å–ç­–ç•¥ (æœ¬åœ° â†’ Pexels â†’ Unsplash â†’ DALL-E)
"""

import json
from typing import Dict, Any, List, Optional
import sys
import os

# å¯¼å…¥AIå®¢æˆ·ç«¯
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '1_script_generator'))
from ai_client import AIClient

# å¯¼å…¥å¤–éƒ¨ç´ æè·å–å™¨
try:
    from pexels_fetcher import PexelsFetcher
    PEXELS_AVAILABLE = True
except ImportError:
    PEXELS_AVAILABLE = False
    print("âš ï¸  Pexelsæ¨¡å—æœªåŠ è½½")

try:
    from unsplash_fetcher import UnsplashFetcher
    UNSPLASH_AVAILABLE = True
except ImportError:
    UNSPLASH_AVAILABLE = False
    print("âš ï¸  Unsplashæ¨¡å—æœªåŠ è½½")


class MaterialRecommender:
    """ç´ ææ¨èå™¨ (æ™ºèƒ½å››çº§è·å–)"""

    def __init__(self, material_manager, config_path: str = 'config/settings.json'):
        """
        åˆå§‹åŒ–æ¨èå™¨

        Args:
            material_manager: ç´ æç®¡ç†å™¨å®ä¾‹
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.material_manager = material_manager
        self.config_path = config_path

        # åŠ è½½é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)

        # åŠ è½½æ¨¡æ¿
        template_path = 'config/templates.json'
        with open(template_path, 'r', encoding='utf-8') as f:
            self.templates = json.load(f)

        # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
        self.ai_client = AIClient(self.config['ai'])

        # åˆå§‹åŒ–å¤–éƒ¨ç´ æè·å–å™¨
        self.pexels_fetcher = PexelsFetcher(config_path) if PEXELS_AVAILABLE else None
        self.unsplash_fetcher = UnsplashFetcher(config_path) if UNSPLASH_AVAILABLE else None

        # V5.5: åˆå§‹åŒ–AIå®¡æ ¸å™¨å’Œç”Ÿæˆå™¨ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
        self._ai_reviewer = None
        self._ai_generator = None

        # V5.6: åˆå§‹åŒ–AIè¯­ä¹‰åŒ¹é…å™¨ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
        self._ai_semantic_matcher = None

        # æ™ºèƒ½è·å–é…ç½®
        self.smart_fetch_config = self.config.get('smart_material_fetch', {
            'enable': True,
            'auto_download': True,
            'prefer_videos': True,
            'min_local_results': 3
        })

    @property
    def ai_reviewer(self):
        """å»¶è¿ŸåŠ è½½AIå®¡æ ¸å™¨"""
        if self._ai_reviewer is None:
            try:
                from ai_reviewer import MaterialReviewerAI
                self._ai_reviewer = MaterialReviewerAI(self.config_path)
            except Exception as e:
                print(f"   âš ï¸  AIå®¡æ ¸å™¨åŠ è½½å¤±è´¥: {str(e)}")
                self._ai_reviewer = None
        return self._ai_reviewer

    @property
    def ai_generator(self):
        """å»¶è¿ŸåŠ è½½AIç”Ÿæˆå™¨"""
        if self._ai_generator is None:
            try:
                from ai_content_generator import AIContentGenerator
                self._ai_generator = AIContentGenerator(self.config_path)
            except Exception as e:
                print(f"   âš ï¸  AIç”Ÿæˆå™¨åŠ è½½å¤±è´¥: {str(e)}")
                self._ai_generator = None
        return self._ai_generator

    @property
    def ai_semantic_matcher(self):
        """å»¶è¿ŸåŠ è½½AIè¯­ä¹‰åŒ¹é…å™¨ï¼ˆV5.6ï¼‰"""
        if self._ai_semantic_matcher is None:
            try:
                from ai_semantic_matcher import AISemanticMatcher
                self._ai_semantic_matcher = AISemanticMatcher(self.config_path)
            except Exception as e:
                print(f"   âš ï¸  AIè¯­ä¹‰åŒ¹é…å™¨åŠ è½½å¤±è´¥: {str(e)}")
                self._ai_semantic_matcher = None
        return self._ai_semantic_matcher

    def recommend_for_script_section(
        self,
        script_section: Dict[str, Any],
        limit: int = 5,
        enable_smart_fetch: bool = True
    ) -> List[Dict[str, Any]]:
        """
        ä¸ºè„šæœ¬ç« èŠ‚æ¨èç´ æ (æ™ºèƒ½å››çº§è·å–)
        V5.6: æ”¯æŒvisual_optionså¤šå±‚æ¬¡åœºæ™¯åŒ¹é…

        Args:
            script_section: è„šæœ¬ç« èŠ‚æ•°æ®
            limit: æ¨èæ•°é‡
            enable_smart_fetch: æ˜¯å¦å¯ç”¨æ™ºèƒ½è·å– (ä»å¤–éƒ¨API)

        Returns:
            æ¨èç´ æåˆ—è¡¨
        """
        section_name = script_section.get('section_name', 'N/A')
        print(f"\nğŸ” åˆ†æç´ æéœ€æ±‚...")
        print(f"   ç« èŠ‚: {section_name}")

        # V5.6: æ£€æŸ¥æ˜¯å¦æœ‰visual_optionsï¼ˆæ–°æ ¼å¼ï¼‰
        visual_options = script_section.get('visual_options', [])
        if visual_options:
            # ä½¿ç”¨æ–°çš„å¤šå±‚æ¬¡åœºæ™¯åŒ¹é…
            return self._recommend_with_visual_options(
                script_section,
                visual_options,
                limit,
                enable_smart_fetch
            )

        # é™çº§åˆ°æ—§ç‰ˆåŒ¹é…é€»è¾‘ï¼ˆå…¼å®¹æ—§è„šæœ¬ï¼‰
        # æå–å…³é”®ä¿¡æ¯
        narration = script_section.get('narration', '')
        visual_notes = script_section.get('visual_notes', '')

        # åˆ†æéœ€è¦çš„ç´ æç±»å‹
        material_requirements = self._analyze_requirements(narration, visual_notes)

        recommendations = []

        # ğŸ”¹ ç¬¬ä¸€çº§: æœ¬åœ°ç´ æåº“æœç´¢
        print("   ğŸ“ [1/4] æœç´¢æœ¬åœ°ç´ æåº“...")
        keywords = material_requirements.get('keywords', [])
        for keyword in keywords:
            materials = self.material_manager.search_materials(keyword)
            recommendations.extend(materials)

        # åŸºäºæ ‡ç­¾æœç´¢
        tags = material_requirements.get('tags', [])
        if tags:
            materials = self.material_manager.list_materials(tags=tags)
            recommendations.extend(materials)

        # å»é‡å¹¶è¯„åˆ†æ’åº
        unique_materials = self._deduplicate_and_score(
            recommendations,
            material_requirements
        )

        print(f"       âœ“ æ‰¾åˆ° {len(unique_materials)} ä¸ªæœ¬åœ°ç´ æ")

        # ğŸ”¹ æ™ºèƒ½è·å–ç­–ç•¥ (å¦‚æœæœ¬åœ°ç´ æä¸è¶³)
        min_required = self.smart_fetch_config.get('min_local_results', 3)

        if enable_smart_fetch and self.smart_fetch_config.get('enable', True) and len(unique_materials) < min_required:
            print(f"       âš ï¸  æœ¬åœ°ç´ æä¸è¶³ (éœ€è¦{min_required}ä¸ª,ä»…{len(unique_materials)}ä¸ª)")

            # æå–è‹±æ–‡å…³é”®è¯(Pexels/Unsplashéœ€è¦è‹±æ–‡)
            search_keyword = self._extract_english_keyword(narration, visual_notes)

            # ğŸ”¹ ç¬¬äºŒçº§: Pexelsè§†é¢‘æœç´¢ (ä¼˜å…ˆè§†é¢‘)
            if self.smart_fetch_config.get('prefer_videos', True) and self.pexels_fetcher:
                pexels_materials = self._fetch_from_pexels_videos(
                    search_keyword,
                    count=limit - len(unique_materials)
                )
                unique_materials.extend(pexels_materials)
                print(f"       âœ“ ä»Pexelsè§†é¢‘è·å– {len(pexels_materials)} ä¸ª")

            # ğŸ”¹ ç¬¬ä¸‰çº§: Pexels/Unsplashå›¾ç‰‡ (å¦‚æœä»ä¸è¶³)
            if len(unique_materials) < limit:
                if self.pexels_fetcher:
                    pexels_photos = self._fetch_from_pexels_photos(
                        search_keyword,
                        count=max(2, limit - len(unique_materials))
                    )
                    unique_materials.extend(pexels_photos)
                    print(f"       âœ“ ä»Pexelså›¾ç‰‡è·å– {len(pexels_photos)} ä¸ª")

                if self.unsplash_fetcher and len(unique_materials) < limit:
                    unsplash_photos = self._fetch_from_unsplash(
                        search_keyword,
                        count=limit - len(unique_materials)
                    )
                    unique_materials.extend(unsplash_photos)
                    print(f"       âœ“ ä»Unsplashè·å– {len(unsplash_photos)} ä¸ª")

            # ğŸ”¹ ç¬¬å››çº§: DALL-Eç”Ÿæˆ (æœ€åæ‰‹æ®µ,ä»˜è´¹)
            # æš‚æ—¶æ³¨é‡Š,é¿å…è‡ªåŠ¨äº§ç”Ÿè´¹ç”¨
            # if len(unique_materials) < limit:
            #     print("       ğŸ’° å¯é€‰: ä½¿ç”¨DALL-Eç”Ÿæˆ (éœ€æ‰‹åŠ¨è§¦å‘)")

        # V5.4ä¿®å¤: ç¡®ä¿æ‰€æœ‰ç´ æéƒ½æœ‰match_scoreå’Œmatch_reason
        # å¤–éƒ¨ç´ æï¼ˆPexels/Unsplashï¼‰éœ€è¦é‡æ–°è¯„åˆ†
        for material in unique_materials:
            if 'match_score' not in material or 'match_reason' not in material:
                material['match_score'] = self._calculate_match_score(material, material_requirements)
                material['match_reason'] = self._generate_match_reason(material, material_requirements)

        # é‡æ–°æ’åºï¼ˆå¤–éƒ¨ç´ æå¯èƒ½è¯„åˆ†æ›´é«˜ï¼‰
        unique_materials.sort(key=lambda x: x.get('match_score', 0), reverse=True)

        # V5.5: AIå®¡æ ¸å’Œç”Ÿæˆ
        final_materials = self._apply_ai_review_and_generation(
            unique_materials[:limit],
            script_section,
            material_requirements
        )

        return final_materials[:limit]

    def _apply_ai_review_and_generation(
        self,
        materials: List[Dict[str, Any]],
        script_section: Dict[str, Any],
        requirements: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        åº”ç”¨AIå®¡æ ¸å’Œç”Ÿæˆï¼ˆV5.5æ–°å¢ï¼‰

        å·¥ä½œæµç¨‹:
        1. AIå®¡æ ¸ç°æœ‰ç´ æ
        2. å¦‚æœæ²¡æœ‰åˆæ ¼ç´ æï¼ŒAIç”Ÿæˆæ–°ç´ æ
        3. è¿”å›æœ€ç»ˆç´ æåˆ—è¡¨

        Args:
            materials: å€™é€‰ç´ æåˆ—è¡¨
            script_section: è„šæœ¬ç« èŠ‚
            requirements: éœ€æ±‚åˆ†æç»“æœ

        Returns:
            æœ€ç»ˆç´ æåˆ—è¡¨
        """
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨AIå®¡æ ¸
        if not self.config.get('smart_material_selection', {}).get('enable_ai_review', False):
            return materials

        # æ‰§è¡ŒAIå®¡æ ¸
        if self.ai_reviewer:
            try:
                review_result = self.ai_reviewer.review_materials(materials, script_section)

                # æœ‰åˆæ ¼ç´ æï¼Œè¿”å›åˆæ ¼åˆ—è¡¨
                if review_result['approved']:
                    approved = review_result['approved']
                    # å°†æœ€ä½³ç´ ææ”¾åœ¨é¦–ä½
                    if review_result['best_material']:
                        best = review_result['best_material']
                        approved = [best] + [m for m in approved if m['id'] != best['id']]
                    return approved

                # æ— åˆæ ¼ç´ æï¼Œå°è¯•AIç”Ÿæˆ
                if review_result.get('need_generation', False) and self.ai_generator:
                    generation_prompt = review_result.get('generation_prompt', '')
                    if not generation_prompt:
                        print(f"   âš ï¸  æ— ç”Ÿæˆæç¤ºè¯ï¼Œè·³è¿‡AIç”Ÿæˆ")
                    else:
                        print(f"\n   ğŸ¨ ç°æœ‰ç´ æä¸ç¬¦åˆè¦æ±‚ï¼Œå°è¯•AIç”Ÿæˆ...")
                        generated = self.ai_generator.generate_material(
                            script_section,
                            generation_prompt
                        )

                        if generated:
                            # å°†ç”Ÿæˆçš„ç´ ææ·»åŠ åˆ°ç´ æåº“
                            try:
                                self.material_manager.add_material(
                                    name=generated['name'],
                                    file_path=generated['file_path'],
                                    material_type=generated['type'],
                                    tags=generated['tags'],
                                    description=generated['description']
                                )
                                print(f"   âœ… AIç”Ÿæˆçš„ç´ æå·²æ·»åŠ åˆ°ç´ æåº“")
                            except Exception as e:
                                print(f"   âš ï¸  æ·»åŠ åˆ°ç´ æåº“å¤±è´¥: {str(e)}")

                            # è¿”å›ç”Ÿæˆçš„ç´ æ
                            return [generated]

            except Exception as e:
                print(f"   âš ï¸  AIå®¡æ ¸/ç”Ÿæˆå¤±è´¥: {str(e)}")

        # é™çº§ï¼šè¿”å›åŸå§‹ç´ æ
        return materials

    def recommend_for_full_script(
        self,
        script: Dict[str, Any]
    ) -> Dict[str, List[Dict[str, Any]]]:
        """
        ä¸ºæ•´ä¸ªè„šæœ¬æ¨èç´ æ

        Args:
            script: å®Œæ•´è„šæœ¬æ•°æ®

        Returns:
            æŒ‰ç« èŠ‚ç»„ç»‡çš„æ¨èç´ æå­—å…¸
        """
        recommendations = {}

        sections = script.get('sections', [])
        for section in sections:
            section_name = section.get('section_name', '')
            recommended = self.recommend_for_script_section(section, limit=3)
            recommendations[section_name] = recommended

        return recommendations

    def suggest_missing_materials(
        self,
        script: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        å»ºè®®éœ€è¦æ·»åŠ çš„ç´ æ

        Args:
            script: è„šæœ¬æ•°æ®

        Returns:
            å»ºè®®åˆ—è¡¨
        """
        suggestions = []

        sections = script.get('sections', [])
        for section in sections:
            section_name = section.get('section_name', '')
            visual_notes = section.get('visual_notes', '')

            # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„ç´ æ
            recommended = self.recommend_for_script_section(section, limit=1)

            if not recommended and visual_notes:
                # æ²¡æœ‰åˆé€‚ç´ æï¼Œå»ºè®®æ·»åŠ 
                suggestions.append({
                    'section': section_name,
                    'visual_requirement': visual_notes,
                    'suggestion_type': 'missing',
                    'action': 'å»ºè®®ä½¿ç”¨AIç”Ÿæˆæˆ–æ‰‹åŠ¨æ·»åŠ ç´ æ'
                })

        return suggestions

    def analyze_material_coverage(
        self,
        script: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        åˆ†æç´ æåº“å¯¹è„šæœ¬çš„è¦†ç›–åº¦

        Args:
            script: è„šæœ¬æ•°æ®

        Returns:
            è¦†ç›–åº¦åˆ†æç»“æœ
        """
        total_sections = len(script.get('sections', []))
        covered_sections = 0
        partially_covered = 0

        coverage_details = []

        for section in script.get('sections', []):
            section_name = section.get('section_name', '')
            recommended = self.recommend_for_script_section(section, limit=3)

            if len(recommended) >= 3:
                covered_sections += 1
                status = 'full'
            elif len(recommended) > 0:
                partially_covered += 1
                status = 'partial'
            else:
                status = 'none'

            coverage_details.append({
                'section': section_name,
                'status': status,
                'available_materials': len(recommended)
            })

        coverage_rate = (covered_sections / total_sections * 100) if total_sections > 0 else 0

        return {
            'total_sections': total_sections,
            'fully_covered': covered_sections,
            'partially_covered': partially_covered,
            'not_covered': total_sections - covered_sections - partially_covered,
            'coverage_rate': round(coverage_rate, 2),
            'details': coverage_details
        }

    def _analyze_requirements(
        self,
        narration: str,
        visual_notes: str
    ) -> Dict[str, Any]:
        """
        åˆ†æç´ æéœ€æ±‚ï¼ˆV5.4å¢å¼ºï¼šå¤šç»´åº¦åˆ†æï¼‰

        Args:
            narration: æ—ç™½æ–‡æœ¬
            visual_notes: è§†è§‰æç¤º

        Returns:
            éœ€æ±‚åˆ†æç»“æœ
        """
        # ä½¿ç”¨AIåˆ†æï¼ˆå¯é€‰ï¼Œä¹Ÿå¯ä»¥ç”¨ç®€å•çš„å…³é”®è¯æå–ï¼‰
        try:
            prompt = f"""
åˆ†æä»¥ä¸‹ç§‘æ™®è§†é¢‘åœºæ™¯éœ€è¦ä»€ä¹ˆç´ æï¼Œå¹¶æå–å¤šç»´åº¦å…³é”®è¯ã€‚

æ—ç™½: {narration[:200]}
è§†è§‰æç¤º: {visual_notes}

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼ˆä¼˜å…ˆæ¨èè§†é¢‘ç´ æï¼‰:
{{
  "material_types": ["video", "image", "animation"],  // æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œä¼˜å…ˆæ¨èvideo
  "keywords": ["ä¸»ä½“å¯¹è±¡", "åœºæ™¯ç±»å‹", "åŠ¨ä½œ/çŠ¶æ€"],  // 3-5ä¸ªå…³é”®è¯
  "tags": ["ç§‘å­¦é¢†åŸŸ", "è§†è§‰é£æ ¼"],  // 2-3ä¸ªæ ‡ç­¾
  "visual_elements": ["å…·ä½“è§†è§‰å…ƒç´ 1", "å…ƒç´ 2"],  // éœ€è¦å±•ç¤ºçš„å…·ä½“å…ƒç´ 
  "scene_type": "å¾®è§‚/å®è§‚/æŠ½è±¡/å®æ™¯",  // åœºæ™¯ç±»å‹
  "mood": "ç§‘æŠ€æ„Ÿ/ç¥ç§˜/æ¸©æš–/ç´§å¼ ",  // æƒ…æ„Ÿæ°›å›´
  "description": "ä¸€å¥è¯æ€»ç»“ç´ æéœ€æ±‚"
}}

ç¤ºä¾‹:
è¾“å…¥: æ—ç™½="DNAåŒèºæ—‹ç»“æ„å­˜å‚¨ç€ç”Ÿå‘½çš„ç§˜å¯†", è§†è§‰="æ˜¾ç¤ºDNAåˆ†å­ç»“æ„æ—‹è½¬åŠ¨ç”»"
è¾“å‡º:
{{
  "material_types": ["video", "animation"],
  "keywords": ["DNA", "åŒèºæ—‹", "åˆ†å­ç»“æ„", "æ—‹è½¬"],
  "tags": ["ç”Ÿç‰©å­¦", "å¾®è§‚", "ç§‘æŠ€"],
  "visual_elements": ["DNAæ¨¡å‹", "èºæ—‹åŠ¨ç”»", "åˆ†å­"],
  "scene_type": "å¾®è§‚",
  "mood": "ç§‘æŠ€æ„Ÿ",
  "description": "DNAåŒèºæ—‹ç»“æ„çš„å¾®è§‚åŠ¨ç”»"
}}
"""
            result = self.ai_client.generate_json(prompt)
            return result

        except:
            # é™çº§åˆ°ç®€å•å…³é”®è¯æå–
            keywords = self._extract_keywords(narration + ' ' + visual_notes)
            return {
                'material_types': ['video', 'image'],  # V5.4: ä¼˜å…ˆè§†é¢‘
                'keywords': keywords,
                'tags': keywords,
                'visual_elements': keywords[:2],
                'scene_type': 'unknown',
                'mood': 'neutral',
                'description': visual_notes or narration[:100]
            }

    def _extract_keywords(self, text: str, max_keywords: int = 5) -> List[str]:
        """
        ç®€å•çš„å…³é”®è¯æå–

        Args:
            text: æ–‡æœ¬
            max_keywords: æœ€å¤§å…³é”®è¯æ•°

        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        # ç®€åŒ–å¤„ç†ï¼šæŒ‰ç©ºæ ¼åˆ†è¯ï¼Œè¿‡æ»¤å¸¸ç”¨è¯
        stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'}

        words = text.split()
        keywords = []

        for word in words:
            if len(word) >= 2 and word not in stop_words and word not in keywords:
                keywords.append(word)
                if len(keywords) >= max_keywords:
                    break

        return keywords

    def _deduplicate_and_score(
        self,
        materials: List[Dict[str, Any]],
        requirements: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        å»é‡å¹¶è¯„åˆ†æ’åºï¼ˆV5.4å¢å¼ºï¼šæ·»åŠ åŒ¹é…åŸå› ï¼‰

        Args:
            materials: ç´ æåˆ—è¡¨
            requirements: éœ€æ±‚åˆ†æç»“æœ

        Returns:
            å»é‡æ’åºåçš„ç´ æåˆ—è¡¨
        """
        # å»é‡
        seen_ids = set()
        unique_materials = []

        for material in materials:
            mat_id = material.get('id')
            if mat_id not in seen_ids:
                seen_ids.add(mat_id)

                # è®¡ç®—åŒ¹é…åˆ†æ•°
                score = self._calculate_match_score(material, requirements)
                material['match_score'] = score

                # V5.4: ç”ŸæˆåŒ¹é…åŸå› 
                material['match_reason'] = self._generate_match_reason(material, requirements)

                unique_materials.append(material)

        # æŒ‰åŒ¹é…åˆ†æ•°æ’åº
        unique_materials.sort(key=lambda x: x.get('match_score', 0), reverse=True)

        return unique_materials

    def _generate_match_reason(
        self,
        material: Dict[str, Any],
        requirements: Dict[str, Any]
    ) -> str:
        """
        ç”Ÿæˆç´ æåŒ¹é…åŸå› è¯´æ˜ï¼ˆV5.4æ–°å¢ï¼‰

        Args:
            material: ç´ ææ•°æ®
            requirements: éœ€æ±‚æ•°æ®

        Returns:
            åŒ¹é…åŸå› æ–‡æœ¬
        """
        reasons = []

        # ç±»å‹åŒ¹é…
        material_type = material.get('type', '')
        if material_type == 'video':
            reasons.append("è§†é¢‘ç´ æ")
        elif material_type == 'image':
            reasons.append("å›¾ç‰‡ç´ æ")

        # æ ‡ç­¾åŒ¹é…
        material_tags = set(material.get('tags', []))
        required_tags = set(requirements.get('tags', []))
        common_tags = material_tags & required_tags
        if common_tags:
            reasons.append(f"æ ‡ç­¾åŒ¹é…: {', '.join(list(common_tags)[:2])}")

        # å…³é”®è¯åŒ¹é…
        material_text = (
            material.get('name', '') + ' ' +
            material.get('description', '') + ' ' +
            ' '.join(material.get('tags', []))
        ).lower()

        keywords = requirements.get('keywords', [])
        matched_keywords = [kw for kw in keywords if kw.lower() in material_text]
        if matched_keywords:
            reasons.append(f"å…³é”®è¯: {', '.join(matched_keywords[:2])}")

        # æ¥æºè¯´æ˜
        source = material.get('source', '')
        if source == 'pexels':
            reasons.append("Pexelsé«˜è´¨é‡")
        elif source == 'unsplash':
            reasons.append("Unsplashé«˜è´¨é‡")

        # ä½¿ç”¨å†å²
        used_count = material.get('used_count', 0)
        if used_count == 0:
            reasons.append("æ–°ç´ æ")
        elif used_count > 5:
            reasons.append(f"å·²ç”¨{used_count}æ¬¡")

        return " | ".join(reasons) if reasons else "åŸºç¡€åŒ¹é…"

    def _calculate_match_score(
        self,
        material: Dict[str, Any],
        requirements: Dict[str, Any]
    ) -> float:
        """
        è®¡ç®—ç´ æä¸éœ€æ±‚çš„åŒ¹é…åˆ†æ•°
        V5.4: å¢å¼ºè¯„åˆ†ç®—æ³• - æ”¯æŒå¤šç»´åº¦åˆ†æ

        Args:
            material: ç´ ææ•°æ®
            requirements: éœ€æ±‚æ•°æ®

        Returns:
            åŒ¹é…åˆ†æ•° (0-100)
        """
        score = 0.0

        # âœ¨ V5.4: ç±»å‹åŒ¹é…ï¼ˆè§†é¢‘ç´ æä¼˜å…ˆï¼Œæƒé‡40åˆ†ï¼‰
        material_type = material.get('type')
        required_types = requirements.get('material_types', [])

        if material_type == 'video':
            # è§†é¢‘åœ¨ç¬¬ä¸€ä¼˜å…ˆçº§ï¼š40åˆ†
            if required_types and required_types[0] == 'video':
                score += 40
            else:
                score += 30  # å³ä½¿ä¸æ˜¯é¦–é€‰ï¼Œè§†é¢‘ä¹Ÿæœ‰é«˜åˆ†
        elif material_type in required_types:
            # å…¶ä»–åŒ¹é…ç±»å‹ï¼š20-30åˆ†
            type_index = required_types.index(material_type)
            score += max(20, 30 - type_index * 5)

        # âœ¨ V5.4: æ ‡ç­¾åŒ¹é…ï¼ˆæƒé‡35åˆ†ï¼‰
        material_tags = set(material.get('tags', []))
        required_tags = set(requirements.get('tags', []))
        tag_overlap = len(material_tags & required_tags)
        if tag_overlap > 0:
            score += min(tag_overlap * 12, 35)

        # âœ¨ V5.4: å…³é”®è¯åŒ¹é…ï¼ˆæƒé‡25åˆ†ï¼‰
        material_text = (
            material.get('name', '') + ' ' +
            material.get('description', '') + ' ' +
            ' '.join(material.get('tags', []))
        ).lower()

        # å…³é”®è¯åŒ¹é…
        keywords = requirements.get('keywords', [])
        keyword_score = 0
        for keyword in keywords:
            keyword_parts = keyword.lower().split()
            matches = sum(1 for part in keyword_parts if part in material_text)
            if matches > 0:
                keyword_score += min(matches * 8, 15)
        score += min(keyword_score, 25)

        # âœ¨ V5.4: è§†è§‰å…ƒç´ åŒ¹é…ï¼ˆæ–°å¢ï¼Œæƒé‡20åˆ†ï¼‰
        visual_elements = requirements.get('visual_elements', [])
        if visual_elements:
            element_score = 0
            for element in visual_elements:
                if element.lower() in material_text:
                    element_score += 10
            score += min(element_score, 20)

        # âœ¨ V5.4: åœºæ™¯ç±»å‹åŒ¹é…ï¼ˆæ–°å¢ï¼Œæƒé‡10åˆ†ï¼‰
        scene_type = requirements.get('scene_type', '').lower()
        if scene_type and scene_type != 'unknown':
            if scene_type in material_text:
                score += 10

        # è¯„åˆ†åŠ æˆï¼ˆæƒé‡10åˆ†ï¼‰
        rating = material.get('rating')
        if rating:
            score += rating * 2

        # âœ¨ V5.4: ä½¿ç”¨å†å²ï¼ˆæƒé‡-15åˆ°+5åˆ†ï¼‰
        used_count = material.get('used_count', 0)
        if used_count == 0:
            score += 5  # æ–°ç´ æåŠ åˆ†
        elif used_count <= 2:
            score += 2  # å°‘ç”¨ç´ æå°åŠ åˆ†
        elif used_count > 5:
            score -= min((used_count - 5) * 3, 15)  # ç”¨å¤ªå¤šæ¬¡å‡åˆ†

        # âœ¨ V5.4: æ¥æºåŠ æˆï¼ˆPexels/Unsplashé«˜è´¨é‡ç´ æï¼‰
        source = material.get('source', '')
        if source == 'pexels' and material_type == 'video':
            score += 5  # Pexelsè§†é¢‘è´¨é‡é«˜
        elif source == 'unsplash':
            score += 3  # Unsplashå›¾ç‰‡è´¨é‡é«˜

        return max(0, min(score, 100))

    # ===== V5.1 æ–°å¢: å¤–éƒ¨ç´ æè·å–æ–¹æ³• =====

    def _extract_english_keyword(self, narration: str, visual_notes: str) -> str:
        """
        æå–è‹±æ–‡å…³é”®è¯(ç”¨äºPexels/Unsplashæœç´¢)
        V5.3: æ·»åŠ AIæ™ºèƒ½æå– + å¤šå…³é”®è¯åŒ¹é… + è¯¦ç»†æ—¥å¿—

        Args:
            narration: æ—ç™½æ–‡æœ¬
            visual_notes: è§†è§‰æç¤º

        Returns:
            è‹±æ–‡å…³é”®è¯
        """
        # ä¼˜å…ˆä½¿ç”¨visual_notes
        text = visual_notes if visual_notes else narration

        print(f"\n   ğŸ” å…³é”®è¯æå–åˆ†æ:")
        print(f"      è¾“å…¥æº: {'visual_notes' if visual_notes else 'narration'}")
        print(f"      æ–‡æœ¬: {text[:120]}{'...' if len(text) > 120 else ''}")

        # âœ¨ V5.3 æ–°å¢: AIæ™ºèƒ½æå– (ä¼˜å…ˆçº§æœ€é«˜)
        ai_keyword = self._ai_extract_keyword(text, narration)
        if ai_keyword:
            print(f"      âœ“ AIæå–: '{ai_keyword}'")
            return ai_keyword

        # ç®€å•æ˜ å°„(ä¸­æ–‡ â†’ è‹±æ–‡ç§‘æ™®å…³é”®è¯)
        # âœ¨ V5.2 æ‰©å±•: æ·»åŠ æ›´å¤šæ°”å€™å’Œç§‘å­¦ç›¸å…³å…³é”®è¯
        keyword_map = {
            # å®‡å®™å’Œå¤©æ–‡
            'å®‡å®™': 'space universe',
            'æ˜Ÿç©º': 'stars galaxy',
            'å¤ªç©º': 'space',
            'é»‘æ´': 'black hole',
            'æ˜Ÿç³»': 'galaxy',
            'è¡Œæ˜Ÿ': 'planet',
            'æ’æ˜Ÿ': 'star',

            # ç”Ÿç‰©å’ŒåŒ»å­¦
            'DNA': 'DNA genetics',
            'åŸºå› ': 'DNA genetics',
            'ç»†èƒ': 'cell biology',
            'å¤§è„‘': 'brain neuroscience',
            'ç¥ç»': 'neuron brain',
            'åŒ»å­¦': 'medicine medical',
            'å¥åº·': 'health medical',
            'å¿ƒè„': 'heart cardiology',
            'è‚º': 'lungs respiratory',
            'è¡€æ¶²': 'blood circulation',

            # ç‰©ç†å’ŒåŒ–å­¦
            'é‡å­': 'quantum physics',
            'ç‰©ç†': 'physics',
            'åŒ–å­¦': 'chemistry science',
            'åˆ†å­': 'molecule chemistry',
            'åŸå­': 'atom physics',
            'ç”µå­': 'electron technology',
            'å…‰': 'light optics',
            'å£°éŸ³': 'sound wave',
            'ç”µ': 'electricity energy',
            'ç›¸å¯¹è®º': 'relativity physics',
            'æ—¶ç©º': 'spacetime physics',

            # ç§‘æŠ€å’ŒAI
            'ç§‘æŠ€': 'technology innovation',
            'äººå·¥æ™ºèƒ½': 'artificial intelligence AI',
            'AI': 'artificial intelligence',
            'æœºå™¨äºº': 'robot technology',
            'è®¡ç®—æœº': 'computer technology',
            'é‡å­è®¡ç®—': 'quantum computing',

            # ç¯å¢ƒå’Œæ°”å€™ (é‡ç‚¹æ‰©å±•)
            'æ°”å€™': 'climate weather',
            'æ°”å€™å˜åŒ–': 'climate change global warming',
            'å…¨çƒå˜æš–': 'global warming',
            'æ¸©å®¤æ•ˆåº”': 'greenhouse effect',
            'æ¸©å®¤æ°”ä½“': 'greenhouse gas emissions',
            'ç¢³æ’æ”¾': 'carbon emissions',
            'äºŒæ°§åŒ–ç¢³': 'carbon dioxide CO2',
            'ç¯å¢ƒ': 'environment nature',
            'ç”Ÿæ€': 'ecology ecosystem',
            'æ±¡æŸ“': 'pollution',
            'å¯å†ç”Ÿèƒ½æº': 'renewable energy',
            'å¤ªé˜³èƒ½': 'solar energy',
            'é£èƒ½': 'wind energy',
            'å†°å·': 'glacier ice',
            'æµ·å¹³é¢': 'sea level',
            'æç«¯å¤©æ°”': 'extreme weather',

            # åœ°çƒç§‘å­¦
            'åœ°çƒ': 'earth planet',
            'æµ·æ´‹': 'ocean sea',
            'ç«å±±': 'volcano',
            'åœ°éœ‡': 'earthquake',
            'åœ°è´¨': 'geology',
            'çŸ¿ç‰©': 'mineral',

            # èƒ½æº
            'èƒ½æº': 'energy renewable',
            'æ ¸èƒ½': 'nuclear energy',
            'ç”µæ± ': 'battery energy storage',

            # âœ¨ V5.3 æ–°å¢: è§†è§‰å…ƒç´ å’ŒåŠ¨ä½œ
            'æ¸©åº¦è®¡': 'thermometer temperature',
            'æ¸©åº¦': 'temperature',
            'æ¸©åº¦ä¸Šå‡': 'rising temperature',
            'ä¸Šå‡': 'rising increase',
            'ä¸‹é™': 'falling decrease',
            'å‘çƒ§': 'fever heat warming',
            'æ±½è½¦': 'car vehicle',
            'é˜³å…‰': 'sunlight solar',
            'ç»ç’ƒ': 'glass transparent',
            'å¤§æ°”å±‚': 'atmosphere',
            'å¤§æ°”': 'atmosphere air',
            'è¾å°„': 'radiation',
            'èåŒ–': 'melting ice',
            'è’¸å‘': 'evaporation',
            'å¾ªç¯': 'cycle circulation',
            'åŠ¨ç”»': 'animation motion',
            'å›¾è¡¨': 'chart graph data',
            'æ›²çº¿': 'curve line graph',
            'æ•°æ®': 'data statistics',
            'å¯¹æ¯”': 'comparison before after',
            'å˜åŒ–': 'change transformation',
            'è¿‡ç¨‹': 'process',
            'å®éªŒ': 'experiment science',
            'æ˜¾å¾®é•œ': 'microscope',
            'æœ›è¿œé•œ': 'telescope'
        }

        # âœ¨ V5.3 æ”¹è¿›: å¤šå…³é”®è¯åŒ¹é… (æ”¶é›†æ‰€æœ‰åŒ¹é…)
        matched_keywords = []
        for cn_keyword, en_keyword in keyword_map.items():
            if cn_keyword in text:
                # è®°å½•: (ä¸­æ–‡è¯, è‹±æ–‡è¯, è¯é•¿åº¦, åœ¨æ–‡æœ¬ä¸­çš„ä½ç½®)
                position = text.index(cn_keyword)
                matched_keywords.append({
                    'cn': cn_keyword,
                    'en': en_keyword,
                    'len': len(cn_keyword),
                    'pos': position
                })

        if matched_keywords:
            # æŒ‰å…³é”®è¯é•¿åº¦æ’åº (ä¼˜å…ˆåŒ¹é…æ›´å…·ä½“çš„é•¿è¯)
            matched_keywords.sort(key=lambda x: x['len'], reverse=True)

            # æ—¥å¿—æ˜¾ç¤ºæ‰€æœ‰åŒ¹é…
            print(f"      åŒ¹é…è¯: {', '.join([f'{m['cn']}â†’{m['en']}' for m in matched_keywords[:5]])}")

            # ç»„åˆå‰2ä¸ªæœ€ç›¸å…³çš„å…³é”®è¯
            top_matches = matched_keywords[:2]
            combined_keyword = ' '.join([m['en'] for m in top_matches])

            print(f"      âœ“ æ˜ å°„è¡¨æå–: '{combined_keyword}'")
            return combined_keyword

        # é»˜è®¤: é€šç”¨ç§‘æ™®å…³é”®è¯
        print(f"      âš ï¸  æ— åŒ¹é…ï¼Œä½¿ç”¨é»˜è®¤: 'science education'")
        return 'science education'

    def _check_material_exists(self, material_id: str) -> Optional[Dict[str, Any]]:
        """
        æ£€æŸ¥ç´ ææ˜¯å¦å·²å­˜åœ¨æ•°æ®åº“ï¼ˆV5.4æ–°å¢ï¼‰

        Args:
            material_id: ç´ æIDï¼ˆå¦‚ pexels_video_29541711ï¼‰

        Returns:
            ç´ æä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¦åˆ™è¿”å›None
        """
        # ç²¾ç¡®IDåŒ¹é…ï¼ˆé€šè¿‡nameå­—æ®µï¼‰
        materials = self.material_manager.search_materials(material_id, search_in=['name'])

        for material in materials:
            # ç²¾ç¡®åŒ¹é…name
            if material.get('name') == material_id:
                # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                file_path = material.get('file_path')
                if file_path and os.path.exists(file_path):
                    return material

        return None

    def _generate_smart_tags(self, keyword: str, material_type: str) -> List[str]:
        """
        ç”Ÿæˆæ™ºèƒ½æ ‡ç­¾ï¼ˆV5.5æ–°å¢ï¼‰

        å°†æœç´¢å…³é”®è¯æ‹†åˆ†ä¸ºç‹¬ç«‹æ ‡ç­¾ï¼Œå¹¶æ·»åŠ åˆ†ç±»æ ‡ç­¾

        Args:
            keyword: æœç´¢å…³é”®è¯ï¼ˆå¦‚"black hole animation"ï¼‰
            material_type: ç´ æç±»å‹ï¼ˆvideo/imageï¼‰

        Returns:
            æ™ºèƒ½æ ‡ç­¾åˆ—è¡¨

        ç¤ºä¾‹:
            è¾“å…¥: "black hole animation", "video"
            è¾“å‡º: ["black", "hole", "animation", "black_hole",
                   "hole_animation", "astronomy", "space", "science", "video"]
        """
        tags = []

        # 1. æ‹†åˆ†ä¸ºç‹¬ç«‹å•è¯
        words = [w.strip().lower() for w in keyword.split() if w.strip()]
        tags.extend(list(set(words)))  # å»é‡

        # 2. æ·»åŠ åŒè¯ç»„åˆï¼ˆé‡è¦ï¼æé«˜ç²¾ç¡®åŒ¹é…ï¼‰
        if len(words) >= 2:
            for i in range(len(words) - 1):
                combined = f"{words[i]}_{words[i+1]}"
                tags.append(combined)

        # 3. æ·»åŠ åˆå¹¶è¯ï¼ˆæ— ç©ºæ ¼ï¼‰
        if len(words) >= 2:
            tags.append(''.join(words[:2]))  # å¦‚ "blackhole"

        # 4. è‡ªåŠ¨åˆ†ç±»æ ‡ç­¾
        category_keywords = {
            'astronomy': ['space', 'star', 'galaxy', 'planet', 'asteroid', 'comet', 'nebula',
                         'black', 'hole', 'sun', 'moon', 'cosmos', 'universe', 'stellar'],
            'biology': ['brain', 'neuron', 'cell', 'DNA', 'gene', 'protein', 'organism',
                       'bacteria', 'virus', 'blood', 'heart', 'organ', 'tissue'],
            'physics': ['atom', 'quantum', 'particle', 'energy', 'wave', 'field',
                       'relativity', 'gravity', 'force', 'motion'],
            'chemistry': ['molecule', 'chemical', 'reaction', 'element', 'compound',
                         'bond', 'acid', 'base'],
            'environment': ['climate', 'weather', 'earth', 'ocean', 'forest', 'pollution',
                           'ecosystem', 'carbon', 'greenhouse', 'renewable'],
            'technology': ['computer', 'robot', 'AI', 'digital', 'network', 'data',
                          'algorithm', 'software']
        }

        # åŒ¹é…åˆ†ç±»
        matched_categories = []
        for category, keywords_list in category_keywords.items():
            if any(kw in keyword.lower() for kw in keywords_list):
                matched_categories.append(category)
                tags.append(category)

        # æ·»åŠ é€šç”¨"science"æ ‡ç­¾ï¼ˆå¦‚æœæœ‰ä»»ä½•ç§‘å­¦åˆ†ç±»ï¼‰
        if matched_categories:
            tags.append('science')

        # 5. æ·»åŠ è§†è§‰ç‰¹å¾æ ‡ç­¾
        visual_keywords = {
            'animation': ['animation', 'animated', 'motion'],
            'abstract': ['abstract', 'pattern', 'texture'],
            'macro': ['macro', 'microscopic', 'close-up', 'micro'],
            'aerial': ['aerial', 'drone', 'bird-eye', 'top-view'],
            'timelapse': ['timelapse', 'time-lapse', 'fast']
        }

        for feature, feature_keywords in visual_keywords.items():
            if any(kw in keyword.lower() for kw in feature_keywords):
                tags.append(feature)

        # 6. æ·»åŠ ç±»å‹æ ‡ç­¾
        tags.append(material_type)

        # 7. å»é‡å¹¶è¿”å›
        return list(set(tags))

    def _ai_extract_keyword(self, visual_notes: str, narration: str) -> Optional[str]:
        """
        ä½¿ç”¨AIæ™ºèƒ½æå–è‹±æ–‡å…³é”®è¯
        V5.5ä¼˜åŒ–ï¼šæ›´ç²¾ç¡®çš„æœç´¢å…³é”®è¯æå–ï¼Œæé«˜Pexels/UnsplashåŒ¹é…ç‡

        Args:
            visual_notes: è§†è§‰æç¤º
            narration: æ—ç™½æ–‡æœ¬

        Returns:
            è‹±æ–‡å…³é”®è¯æˆ–None
        """
        try:
            prompt = f"""ä½ æ˜¯ç´ ææœç´¢ä¸“å®¶ã€‚åˆ†æä»¥ä¸‹ç§‘æ™®è§†é¢‘åœºæ™¯ï¼Œæå–æœ€é€‚åˆåœ¨Pexels/Unsplashæœç´¢çš„è‹±æ–‡å…³é”®è¯ã€‚

## åœºæ™¯ä¿¡æ¯
è§†è§‰éœ€æ±‚: {visual_notes[:200]}
æ—ç™½å†…å®¹: {narration[:100]}

## å…³é”®è¯æå–è§„åˆ™

### 1. ä¼˜å…ˆçº§æ’åº
1) å…·ä½“ç‰©ä½“/ç°è±¡ï¼ˆå¦‚ black hole, DNA molecule, brain scanï¼‰
2) åŠ¨ä½œ/çŠ¶æ€ï¼ˆå¦‚ rotating, glowing, flowingï¼‰
3) åœºæ™¯ç±»å‹ï¼ˆå¦‚ space, laboratory, natureï¼‰
4) è§†è§‰é£æ ¼ï¼ˆå¦‚ animation, abstract, microscopicï¼‰

### 2. é¿å…è¿‡äºä¸“ä¸šçš„æœ¯è¯­
âŒ ä¸å¥½: "accretion disk radiation" â†’ âœ… å¥½: "black hole space"
âŒ ä¸å¥½: "synaptic vesicles" â†’ âœ… å¥½: "neuron brain"
âŒ ä¸å¥½: "anthropogenic forcing" â†’ âœ… å¥½: "climate change earth"

### 3. å…³é”®è¯ç»„åˆç­–ç•¥
- 2-4ä¸ªè¯ä¸ºä½³ï¼ˆå¤ªå°‘â†’ç»“æœå¤ªæ³›ï¼Œå¤ªå¤šâ†’æ— ç»“æœï¼‰
- æ ¸å¿ƒå¯¹è±¡ + ä¿®é¥°è¯ï¼ˆå¦‚ "space nebula colorful"ï¼‰
- ä¼˜å…ˆè§†é¢‘å…³é”®è¯ï¼ˆåŠ  "motion" "animation" "4k"ï¼‰

### 4. å¸¸è§ç§‘æ™®ä¸»é¢˜æ˜ å°„
- é»‘æ´/æ—¶ç©º â†’ black hole space gravity
- DNA/åŸºå›  â†’ DNA helix molecule biology
- å¤§è„‘/ç¥ç» â†’ brain neuron medical
- æ°”å€™å˜åŒ– â†’ climate earth temperature
- åŸå­/ç²’å­ â†’ atom particle physics
- ç»†èƒ â†’ cell biology microscopic
- æ˜Ÿç³»/å®‡å®™ â†’ galaxy space stars

## è¾“å‡ºæ ¼å¼
**åªè¾“å‡º2-4ä¸ªè‹±æ–‡å…³é”®è¯ï¼Œç”¨ç©ºæ ¼åˆ†éš”ï¼Œä¸è¦ä»»ä½•æ ‡ç‚¹ã€æ¢è¡Œæˆ–è§£é‡Š**

ç¤ºä¾‹ï¼š
è¾“å…¥: "å±•ç¤ºé»‘æ´å¸ç§¯ç›˜çš„å£®è§‚æ™¯è±¡"
è¾“å‡º: black hole accretion disk space

è¾“å…¥: "DNAåŒèºæ—‹ç»“æ„æ—‹è½¬åŠ¨ç”»"
è¾“å‡º: DNA helix rotation animation

è¾“å…¥: "å¤§è„‘ç¥ç»å…ƒçªè§¦è¿æ¥"
è¾“å‡º: brain neuron synapse connection

ç°åœ¨è¯·æå–ï¼ˆå•è¡Œè¾“å‡ºï¼‰:"""

            result = self.ai_client.generate(prompt).strip()

            # æ¸…æ´—å’ŒéªŒè¯ç»“æœ
            if not result:
                return None

            # ç§»é™¤ä¸­æ–‡æ ‡ç‚¹
            result = result.replace('ã€‚', ' ').replace('ï¼Œ', ' ').replace(',', ' ')

            # å¤„ç†å¤šè¡Œï¼šå¦‚æœæœ‰æ¢è¡Œï¼Œå–ç¬¬ä¸€ä¸ªéç©ºè¡Œæˆ–åˆå¹¶æ‰€æœ‰è¡Œ
            if '\n' in result:
                lines = [line.strip() for line in result.split('\n') if line.strip()]
                if lines:
                    # å¦‚æœç¬¬ä¸€è¡Œçœ‹èµ·æ¥æ˜¯å®Œæ•´çš„å…³é”®è¯ï¼Œä½¿ç”¨ç¬¬ä¸€è¡Œ
                    first_line = lines[0]
                    if len(first_line) < 100 and ' ' in first_line:
                        result = first_line
                        print(f"      â„¹ï¸  AIè¿”å›å¤šè¡Œï¼Œå·²å–ç¬¬ä¸€è¡Œ: {result}")
                    else:
                        # å¦åˆ™åˆå¹¶æ‰€æœ‰è¡Œ
                        result = ' '.join(lines)
                        print(f"      â„¹ï¸  AIè¿”å›å¤šè¡Œï¼Œå·²åˆå¹¶: {result[:50]}")

            # æœ€ç»ˆéªŒè¯
            result = ' '.join(result.split())  # æ ‡å‡†åŒ–ç©ºæ ¼
            if result and len(result) < 150 and not any(c in result for c in ['ã€‚', 'ï¼Œ', 'ï¼š', ':']):
                return result
            else:
                print(f"      âš ï¸  AIè¿”å›æ ¼å¼å¼‚å¸¸: {result[:50]}")
                return None

        except Exception as e:
            print(f"      âš ï¸  AIæå–å¤±è´¥: {str(e)}")
            return None

    def _fetch_from_pexels_videos(self, keyword: str, count: int = 3) -> List[Dict[str, Any]]:
        """
        ä»Pexelsè·å–è§†é¢‘ç´ æï¼ˆV5.4ï¼šä¼˜åŒ–é‡å¤ä¸‹è½½æ£€æŸ¥ï¼‰

        Args:
            keyword: è‹±æ–‡å…³é”®è¯
            count: æ•°é‡

        Returns:
            ç´ æä¿¡æ¯åˆ—è¡¨(å·²è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼)
        """
        if not self.pexels_fetcher:
            return []

        try:
            print(f"   ğŸ¥ [2/4] ä»Pexelsæœç´¢è§†é¢‘: '{keyword}'...")

            # æœç´¢
            videos = self.pexels_fetcher.search_videos(keyword, per_page=count)

            # è‡ªåŠ¨ä¸‹è½½
            materials = []
            for video in videos[:count]:
                # V5.4: ç»Ÿä¸€ç´ æIDæ ¼å¼
                material_id = f"pexels_video_{video['id']}"

                # V5.4: æ—©æœŸé€€å‡º - å…ˆæ£€æŸ¥æ•°æ®åº“æ˜¯å¦å·²å­˜åœ¨ï¼ˆç²¾ç¡®IDåŒ¹é…ï¼‰
                existing = self._check_material_exists(material_id)
                if existing:
                    print(f"       â­ï¸  å·²å­˜åœ¨æ•°æ®åº“: {material_id}")
                    materials.append(existing)
                    continue

                if self.smart_fetch_config.get('auto_download', True):
                    filepath = self.pexels_fetcher.download_video(video, keyword)
                    if filepath:
                        # V5.5: ä½¿ç”¨æ™ºèƒ½æ ‡ç­¾ç³»ç»Ÿ
                        smart_tags = self._generate_smart_tags(keyword, 'video')

                        # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
                        material_data = {
                            'id': material_id,
                            'name': material_id,
                            'type': 'video',
                            'file_path': filepath,
                            'tags': smart_tags,  # V5.5: æ™ºèƒ½æ ‡ç­¾
                            'description': f"Pexelsè§†é¢‘: {keyword}",
                            'source': 'pexels',
                            'match_score': 85,
                            'rating': 4,
                            'used_count': 0
                        }
                        materials.append(material_data)

                        # V5.4: æ³¨å†Œåˆ°ç´ æåº“ï¼ˆä¼˜åŒ–æ£€æŸ¥é€»è¾‘ï¼‰
                        try:
                            # å†æ¬¡æ£€æŸ¥ï¼ˆé˜²æ­¢å¹¶å‘é—®é¢˜ï¼‰
                            if not self._check_material_exists(material_id):
                                self.material_manager.add_material(
                                    name=material_id,  # V5.4: ä½¿ç”¨ç»Ÿä¸€ID
                                    file_path=filepath,
                                    material_type='video',
                                    tags=material_data['tags'],
                                    description=material_data['description']
                                )
                                print(f"       âœ“ å·²æ³¨å†Œåˆ°ç´ æåº“: {material_id}")
                            else:
                                print(f"       â­ï¸  å·²åœ¨æ•°æ®åº“ï¼Œè·³è¿‡æ³¨å†Œ: {material_id}")
                        except Exception as reg_error:
                            print(f"       âš ï¸  æ³¨å†Œå¤±è´¥: {str(reg_error)}")

            return materials

        except Exception as e:
            print(f"       âŒ Pexelsè§†é¢‘è·å–å¤±è´¥: {str(e)}")
            return []

    def _fetch_from_pexels_photos(self, keyword: str, count: int = 3) -> List[Dict[str, Any]]:
        """ä»Pexelsè·å–å›¾ç‰‡ç´ æï¼ˆV5.4ï¼šä¼˜åŒ–é‡å¤ä¸‹è½½æ£€æŸ¥ï¼‰"""
        if not self.pexels_fetcher:
            return []

        try:
            print(f"   ğŸ–¼ï¸  [3/4] ä»Pexelsæœç´¢å›¾ç‰‡: '{keyword}'...")

            photos = self.pexels_fetcher.search_photos(keyword, per_page=count)

            materials = []
            for photo in photos[:count]:
                # V5.4: ç»Ÿä¸€ç´ æIDæ ¼å¼
                material_id = f"pexels_photo_{photo['id']}"

                # V5.4: æ—©æœŸé€€å‡º - å…ˆæ£€æŸ¥æ•°æ®åº“
                existing = self._check_material_exists(material_id)
                if existing:
                    print(f"       â­ï¸  å·²å­˜åœ¨æ•°æ®åº“: {material_id}")
                    materials.append(existing)
                    continue

                if self.smart_fetch_config.get('auto_download', True):
                    filepath = self.pexels_fetcher.download_photo(photo, keyword)
                    if filepath:
                        # V5.5: ä½¿ç”¨æ™ºèƒ½æ ‡ç­¾ç³»ç»Ÿ
                        smart_tags = self._generate_smart_tags(keyword, 'image')

                        material_data = {
                            'id': material_id,
                            'name': material_id,
                            'type': 'image',
                            'file_path': filepath,
                            'tags': smart_tags,  # V5.5: æ™ºèƒ½æ ‡ç­¾
                            'description': f"Pexelså›¾ç‰‡: {keyword}",
                            'source': 'pexels',
                            'match_score': 75,
                            'rating': 4,
                            'used_count': 0
                        }
                        materials.append(material_data)

                        # V5.4: æ³¨å†Œåˆ°ç´ æåº“ï¼ˆä¼˜åŒ–æ£€æŸ¥ï¼‰
                        try:
                            if not self._check_material_exists(material_id):
                                self.material_manager.add_material(
                                    name=material_id,
                                    file_path=filepath,
                                    material_type='image',
                                    tags=material_data['tags'],
                                    description=material_data['description']
                                )
                                print(f"       âœ“ å·²æ³¨å†Œåˆ°ç´ æåº“: {material_id}")
                            else:
                                print(f"       â­ï¸  å·²åœ¨æ•°æ®åº“ï¼Œè·³è¿‡æ³¨å†Œ: {material_id}")
                        except Exception as reg_error:
                            print(f"       âš ï¸  æ³¨å†Œå¤±è´¥: {str(reg_error)}")

            return materials

        except Exception as e:
            print(f"       âŒ Pexelså›¾ç‰‡è·å–å¤±è´¥: {str(e)}")
            return []

    def _fetch_from_unsplash(self, keyword: str, count: int = 3) -> List[Dict[str, Any]]:
        """ä»Unsplashè·å–é«˜è´¨é‡å›¾ç‰‡ï¼ˆV5.4ï¼šä¼˜åŒ–é‡å¤ä¸‹è½½æ£€æŸ¥ï¼‰"""
        if not self.unsplash_fetcher:
            return []

        try:
            print(f"   ğŸ“¸ [3/4] ä»Unsplashæœç´¢å›¾ç‰‡: '{keyword}'...")

            photos = self.unsplash_fetcher.search_photos(keyword, per_page=count)

            materials = []
            for photo in photos[:count]:
                # V5.4: ç»Ÿä¸€ç´ æIDæ ¼å¼
                material_id = f"unsplash_{photo['id']}"

                # V5.4: æ—©æœŸé€€å‡º - å…ˆæ£€æŸ¥æ•°æ®åº“
                existing = self._check_material_exists(material_id)
                if existing:
                    print(f"       â­ï¸  å·²å­˜åœ¨æ•°æ®åº“: {material_id}")
                    materials.append(existing)
                    continue

                if self.smart_fetch_config.get('auto_download', True):
                    filepath = self.unsplash_fetcher.download_photo(photo, keyword, quality='regular')
                    if filepath:
                        # V5.5: ä½¿ç”¨æ™ºèƒ½æ ‡ç­¾ç³»ç»Ÿ
                        smart_tags = self._generate_smart_tags(keyword, 'image')

                        material_data = {
                            'id': material_id,
                            'name': material_id,
                            'type': 'image',
                            'file_path': filepath,
                            'tags': smart_tags,  # V5.5: æ™ºèƒ½æ ‡ç­¾
                            'description': photo.get('description', f"Unsplash: {keyword}"),
                            'source': 'unsplash',
                            'match_score': 80,
                            'rating': 5,  # Unsplashè´¨é‡æœ€é«˜
                            'used_count': 0
                        }
                        materials.append(material_data)

                        # V5.4: æ³¨å†Œåˆ°ç´ æåº“ï¼ˆä¼˜åŒ–æ£€æŸ¥ï¼‰
                        try:
                            if not self._check_material_exists(material_id):
                                self.material_manager.add_material(
                                    name=material_id,
                                    file_path=filepath,
                                    material_type='image',
                                    tags=material_data['tags'],
                                    description=material_data['description']
                                )
                                print(f"       âœ“ å·²æ³¨å†Œåˆ°ç´ æåº“: {material_id}")
                            else:
                                print(f"       â­ï¸  å·²åœ¨æ•°æ®åº“ï¼Œè·³è¿‡æ³¨å†Œ: {material_id}")
                        except Exception as reg_error:
                            print(f"       âš ï¸  æ³¨å†Œå¤±è´¥: {str(reg_error)}")

            return materials

        except Exception as e:
            print(f"       âŒ Unsplashè·å–å¤±è´¥: {str(e)}")
            return []

    def _recommend_with_visual_options(
        self,
        script_section: Dict[str, Any],
        visual_options: List[Dict[str, Any]],
        limit: int,
        enable_smart_fetch: bool
    ) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨visual_optionså¤šå±‚æ¬¡åœºæ™¯è¿›è¡ŒåŒ¹é…ï¼ˆV5.6æ–°å¢ï¼‰

        Args:
            script_section: è„šæœ¬ç« èŠ‚
            visual_options: 3ä¸ªä¼˜å…ˆçº§çš„è§†è§‰æ–¹æ¡ˆ
            limit: è¿”å›æ•°é‡
            enable_smart_fetch: æ˜¯å¦å¯ç”¨å¤–éƒ¨ç´ æè·å–

        Returns:
            æ¨èç´ æåˆ—è¡¨
        """
        section_name = script_section.get('section_name', 'N/A')

        # ç¡®ä¿visual_optionsæœ‰priorityå­—æ®µï¼ˆå®¹é”™å¤„ç†ï¼‰
        for i, opt in enumerate(visual_options):
            if 'priority' not in opt:
                opt['priority'] = i + 1  # æŒ‰é¡ºåºåˆ†é…1, 2, 3

        # æ˜¾ç¤º3ä¸ªä¼˜å…ˆçº§æ–¹æ¡ˆ
        print(f"\n   ğŸ¬ è§†è§‰æ–¹æ¡ˆï¼ˆå¤šå±‚æ¬¡ï¼‰:")
        for opt in visual_options:
            priority = opt.get('priority', 0)
            desc = opt.get('description', '')[:60]
            complexity = opt.get('complexity', 'unknown')
            source = opt.get('suggested_source', '')
            print(f"      Priority {priority} ({complexity}): {desc}... [{source}]")

        # 1. æ”¶é›†å€™é€‰ç´ æï¼ˆåˆå¹¶æ‰€æœ‰ä¼˜å…ˆçº§çš„å…³é”®è¯ï¼‰
        all_keywords = []
        for opt in visual_options:
            all_keywords.extend(opt.get('keywords', []))

        # å»é‡å…³é”®è¯
        all_keywords = list(set(all_keywords))

        # æœç´¢æœ¬åœ°ç´ æåº“
        print(f"\n   ğŸ“ [1/4] æœç´¢æœ¬åœ°ç´ æåº“ (å…³é”®è¯: {', '.join(all_keywords[:5])}...)")
        candidates = []

        for keyword in all_keywords:
            materials = self.material_manager.search_materials(keyword)
            candidates.extend(materials)

        # å»é‡
        seen_ids = set()
        unique_candidates = []
        for mat in candidates:
            mat_id = mat.get('id')
            if mat_id not in seen_ids:
                seen_ids.add(mat_id)
                unique_candidates.append(mat)

        print(f"       âœ“ æ‰¾åˆ° {len(unique_candidates)} ä¸ªæœ¬åœ°ç´ æ")

        # 2. å¤–éƒ¨ç´ æè·å–ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if enable_smart_fetch and len(unique_candidates) < self.smart_fetch_config.get('min_local_results', 3):
            print(f"       âš ï¸  æœ¬åœ°ç´ æä¸è¶³ï¼Œå°è¯•å¤–éƒ¨è·å–...")

            # æŒ‰ä¼˜å…ˆçº§å°è¯•æœç´¢
            for opt in sorted(visual_options, key=lambda x: x.get('priority', 999)):
                if len(unique_candidates) >= limit:
                    break

                keywords = opt.get('keywords', [])
                search_keyword = ' '.join(keywords[:3])  # ä½¿ç”¨å‰3ä¸ªå…³é”®è¯

                # Pexelsè§†é¢‘
                if self.pexels_fetcher and self.smart_fetch_config.get('prefer_videos', True):
                    pexels_videos = self._fetch_from_pexels_videos(
                        search_keyword,
                        count=max(2, limit - len(unique_candidates))
                    )
                    unique_candidates.extend(pexels_videos)

                # Pexelså›¾ç‰‡
                if len(unique_candidates) < limit and self.pexels_fetcher:
                    pexels_photos = self._fetch_from_pexels_photos(
                        search_keyword,
                        count=max(1, limit - len(unique_candidates))
                    )
                    unique_candidates.extend(pexels_photos)

        # 3. AIè¯­ä¹‰åŒ¹é…ï¼ˆæ ¸å¿ƒï¼‰
        print(f"\n   ğŸ§  [AIè¯­ä¹‰åŒ¹é…] åˆ†æ {len(unique_candidates)} ä¸ªå€™é€‰ç´ æ...")

        if not unique_candidates:
            print("       âŒ æœªæ‰¾åˆ°ä»»ä½•å€™é€‰ç´ æ")
            return []

        # ä½¿ç”¨AIè¯­ä¹‰åŒ¹é…å™¨
        if self.ai_semantic_matcher:
            try:
                match_result = self.ai_semantic_matcher.match_scene_to_materials(
                    visual_options,
                    unique_candidates,
                    section_name
                )

                # è§£æåŒ¹é…ç»“æœ
                best_material = match_result.get('best_material')
                selected_priority = match_result.get('selected_priority', 3)
                semantic_score = match_result.get('semantic_score', 0)
                reasoning = match_result.get('reasoning', '')

                if best_material:
                    print(f"       âœ… æœ€ä½³åŒ¹é…: {best_material.get('name', 'N/A')}")
                    print(f"       ğŸ“Š åŒ¹é…Priority {selected_priority} | è¯­ä¹‰è¯„åˆ†: {semantic_score}%")
                    print(f"       ğŸ’¡ AIåˆ†æ: {reasoning[:80]}...")

                    # ä¸ºæœ€ä½³ç´ ææ·»åŠ åŒ¹é…ä¿¡æ¯
                    best_material['match_score'] = semantic_score
                    best_material['matched_priority'] = selected_priority
                    best_material['match_reason'] = reasoning
                    best_material['matched_elements'] = match_result.get('matched_elements', [])
                    best_material['missing_elements'] = match_result.get('missing_elements', [])

                    # æ„å»ºè¿”å›åˆ—è¡¨ï¼ˆæœ€ä½³ç´ æ+å¤‡é€‰ï¼‰
                    result_materials = [best_material]

                    # æ·»åŠ å¤‡é€‰ç´ æ
                    for alt in match_result.get('alternative_matches', [])[:limit-1]:
                        alt_material = alt.get('material')
                        if alt_material:
                            alt_material['match_score'] = alt.get('score', 0)
                            alt_material['matched_priority'] = alt.get('priority', 3)
                            alt_material['match_reason'] = alt.get('reasoning', '')
                            result_materials.append(alt_material)

                    return result_materials[:limit]
                else:
                    print("       âš ï¸  AIæœªæ‰¾åˆ°åˆé€‚åŒ¹é…")

            except Exception as e:
                print(f"       âš ï¸  AIè¯­ä¹‰åŒ¹é…å¼‚å¸¸: {str(e)}")

        # 4. é™çº§åˆ°ä¼ ç»Ÿè¯„åˆ†ï¼ˆAIå¤±è´¥æ—¶ï¼‰
        print("       âš ï¸  ä½¿ç”¨ä¼ ç»Ÿå…³é”®è¯åŒ¹é…...")
        return self._fallback_keyword_matching(visual_options, unique_candidates, limit)

    def _fallback_keyword_matching(
        self,
        visual_options: List[Dict[str, Any]],
        materials: List[Dict[str, Any]],
        limit: int
    ) -> List[Dict[str, Any]]:
        """
        é™çº§åŒ¹é…é€»è¾‘ï¼ˆAIå¤±è´¥æ—¶ä½¿ç”¨å…³é”®è¯åŒ¹é…ï¼‰

        Args:
            visual_options: è§†è§‰æ–¹æ¡ˆ
            materials: å€™é€‰ç´ æ
            limit: è¿”å›æ•°é‡

        Returns:
            æ¨èç´ æåˆ—è¡¨
        """
        # æå–æ‰€æœ‰å…³é”®è¯ï¼ˆä¼˜å…ˆçº§åŠ æƒï¼‰
        weighted_keywords = []
        for opt in visual_options:
            priority = opt.get('priority', 3)
            keywords = opt.get('keywords', [])
            weight = 4 - priority  # Priority 1æƒé‡3ï¼ŒPriority 2æƒé‡2ï¼ŒPriority 3æƒé‡1
            weighted_keywords.extend([(kw.lower(), weight) for kw in keywords])

        # è®¡ç®—æ¯ä¸ªç´ æçš„è¯„åˆ†
        scored_materials = []
        for mat in materials:
            score = 0
            mat_text = (
                mat.get('name', '') + ' ' +
                mat.get('description', '') + ' ' +
                ' '.join(mat.get('tags', []))
            ).lower()

            # å…³é”®è¯åŒ¹é…
            for keyword, weight in weighted_keywords:
                if keyword in mat_text:
                    score += 10 * weight

            # ç±»å‹åŠ åˆ†
            if mat.get('type') == 'video':
                score += 20

            # æ¥æºåŠ åˆ†
            if mat.get('source') in ['pexels', 'unsplash']:
                score += 10

            mat['match_score'] = score
            mat['matched_priority'] = 3  # é™çº§é»˜è®¤Priority 3
            mat['match_reason'] = 'å…³é”®è¯åŒ¹é…ï¼ˆé™çº§æ¨¡å¼ï¼‰'

            scored_materials.append(mat)

        # æ’åºå¹¶è¿”å›
        scored_materials.sort(key=lambda x: x.get('match_score', 0), reverse=True)
        return scored_materials[:limit]
