"""
æ™ºèƒ½ç´ ææ¨èç³»ç»Ÿ
æ ¹æ®è„šæœ¬å†…å®¹æ™ºèƒ½æ¨èåˆé€‚çš„ç´ æ
V5.1 æ–°å¢: å››çº§æ™ºèƒ½è·å–ç­–ç•¥ (æœ¬åœ° â†’ Pexels â†’ Unsplash â†’ DALL-E)
"""

import json
from typing import Dict, Any, List, Optional
import sys
import os

# å¯¼å…¥AIå®¢æˆ·ç«¯
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '1_script_generator'))
from ai_client import AIClient

# å¯¼å…¥å¤–éƒ¨ç´ æè·å–å™¨
try:
    from pexels_fetcher import PexelsFetcher
    PEXELS_AVAILABLE = True
except ImportError:
    PEXELS_AVAILABLE = False
    print("âš ï¸  Pexelsæ¨¡å—æœªåŠ è½½")

try:
    from unsplash_fetcher import UnsplashFetcher
    UNSPLASH_AVAILABLE = True
except ImportError:
    UNSPLASH_AVAILABLE = False
    print("âš ï¸  Unsplashæ¨¡å—æœªåŠ è½½")


class MaterialRecommender:
    """ç´ ææ¨èå™¨ (æ™ºèƒ½å››çº§è·å–)"""

    def __init__(self, material_manager, config_path: str = 'config/settings.json'):
        """
        åˆå§‹åŒ–æ¨èå™¨

        Args:
            material_manager: ç´ æç®¡ç†å™¨å®ä¾‹
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.material_manager = material_manager

        # åŠ è½½é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)

        # åŠ è½½æ¨¡æ¿
        template_path = 'config/templates.json'
        with open(template_path, 'r', encoding='utf-8') as f:
            self.templates = json.load(f)

        # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
        self.ai_client = AIClient(self.config['ai'])

        # åˆå§‹åŒ–å¤–éƒ¨ç´ æè·å–å™¨
        self.pexels_fetcher = PexelsFetcher(config_path) if PEXELS_AVAILABLE else None
        self.unsplash_fetcher = UnsplashFetcher(config_path) if UNSPLASH_AVAILABLE else None

        # æ™ºèƒ½è·å–é…ç½®
        self.smart_fetch_config = self.config.get('smart_material_fetch', {
            'enable': True,
            'auto_download': True,
            'prefer_videos': True,
            'min_local_results': 3
        })

    def recommend_for_script_section(
        self,
        script_section: Dict[str, Any],
        limit: int = 5,
        enable_smart_fetch: bool = True
    ) -> List[Dict[str, Any]]:
        """
        ä¸ºè„šæœ¬ç« èŠ‚æ¨èç´ æ (æ™ºèƒ½å››çº§è·å–)

        Args:
            script_section: è„šæœ¬ç« èŠ‚æ•°æ®
            limit: æ¨èæ•°é‡
            enable_smart_fetch: æ˜¯å¦å¯ç”¨æ™ºèƒ½è·å– (ä»å¤–éƒ¨API)

        Returns:
            æ¨èç´ æåˆ—è¡¨
        """
        # æå–å…³é”®ä¿¡æ¯
        narration = script_section.get('narration', '')
        visual_notes = script_section.get('visual_notes', '')

        # åˆ†æéœ€è¦çš„ç´ æç±»å‹
        material_requirements = self._analyze_requirements(narration, visual_notes)

        print(f"\nğŸ” åˆ†æç´ æéœ€æ±‚...")
        print(f"   ç« èŠ‚: {script_section.get('section_name', 'N/A')}")

        recommendations = []

        # ğŸ”¹ ç¬¬ä¸€çº§: æœ¬åœ°ç´ æåº“æœç´¢
        print("   ğŸ“ [1/4] æœç´¢æœ¬åœ°ç´ æåº“...")
        keywords = material_requirements.get('keywords', [])
        for keyword in keywords:
            materials = self.material_manager.search_materials(keyword)
            recommendations.extend(materials)

        # åŸºäºæ ‡ç­¾æœç´¢
        tags = material_requirements.get('tags', [])
        if tags:
            materials = self.material_manager.list_materials(tags=tags)
            recommendations.extend(materials)

        # å»é‡å¹¶è¯„åˆ†æ’åº
        unique_materials = self._deduplicate_and_score(
            recommendations,
            material_requirements
        )

        print(f"       âœ“ æ‰¾åˆ° {len(unique_materials)} ä¸ªæœ¬åœ°ç´ æ")

        # ğŸ”¹ æ™ºèƒ½è·å–ç­–ç•¥ (å¦‚æœæœ¬åœ°ç´ æä¸è¶³)
        min_required = self.smart_fetch_config.get('min_local_results', 3)

        if enable_smart_fetch and self.smart_fetch_config.get('enable', True) and len(unique_materials) < min_required:
            print(f"       âš ï¸  æœ¬åœ°ç´ æä¸è¶³ (éœ€è¦{min_required}ä¸ª,ä»…{len(unique_materials)}ä¸ª)")

            # æå–è‹±æ–‡å…³é”®è¯(Pexels/Unsplashéœ€è¦è‹±æ–‡)
            search_keyword = self._extract_english_keyword(narration, visual_notes)

            # ğŸ”¹ ç¬¬äºŒçº§: Pexelsè§†é¢‘æœç´¢ (ä¼˜å…ˆè§†é¢‘)
            if self.smart_fetch_config.get('prefer_videos', True) and self.pexels_fetcher:
                pexels_materials = self._fetch_from_pexels_videos(
                    search_keyword,
                    count=limit - len(unique_materials)
                )
                unique_materials.extend(pexels_materials)
                print(f"       âœ“ ä»Pexelsè§†é¢‘è·å– {len(pexels_materials)} ä¸ª")

            # ğŸ”¹ ç¬¬ä¸‰çº§: Pexels/Unsplashå›¾ç‰‡ (å¦‚æœä»ä¸è¶³)
            if len(unique_materials) < limit:
                if self.pexels_fetcher:
                    pexels_photos = self._fetch_from_pexels_photos(
                        search_keyword,
                        count=max(2, limit - len(unique_materials))
                    )
                    unique_materials.extend(pexels_photos)
                    print(f"       âœ“ ä»Pexelså›¾ç‰‡è·å– {len(pexels_photos)} ä¸ª")

                if self.unsplash_fetcher and len(unique_materials) < limit:
                    unsplash_photos = self._fetch_from_unsplash(
                        search_keyword,
                        count=limit - len(unique_materials)
                    )
                    unique_materials.extend(unsplash_photos)
                    print(f"       âœ“ ä»Unsplashè·å– {len(unsplash_photos)} ä¸ª")

            # ğŸ”¹ ç¬¬å››çº§: DALL-Eç”Ÿæˆ (æœ€åæ‰‹æ®µ,ä»˜è´¹)
            # æš‚æ—¶æ³¨é‡Š,é¿å…è‡ªåŠ¨äº§ç”Ÿè´¹ç”¨
            # if len(unique_materials) < limit:
            #     print("       ğŸ’° å¯é€‰: ä½¿ç”¨DALL-Eç”Ÿæˆ (éœ€æ‰‹åŠ¨è§¦å‘)")

        return unique_materials[:limit]

    def recommend_for_full_script(
        self,
        script: Dict[str, Any]
    ) -> Dict[str, List[Dict[str, Any]]]:
        """
        ä¸ºæ•´ä¸ªè„šæœ¬æ¨èç´ æ

        Args:
            script: å®Œæ•´è„šæœ¬æ•°æ®

        Returns:
            æŒ‰ç« èŠ‚ç»„ç»‡çš„æ¨èç´ æå­—å…¸
        """
        recommendations = {}

        sections = script.get('sections', [])
        for section in sections:
            section_name = section.get('section_name', '')
            recommended = self.recommend_for_script_section(section, limit=3)
            recommendations[section_name] = recommended

        return recommendations

    def suggest_missing_materials(
        self,
        script: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        å»ºè®®éœ€è¦æ·»åŠ çš„ç´ æ

        Args:
            script: è„šæœ¬æ•°æ®

        Returns:
            å»ºè®®åˆ—è¡¨
        """
        suggestions = []

        sections = script.get('sections', [])
        for section in sections:
            section_name = section.get('section_name', '')
            visual_notes = section.get('visual_notes', '')

            # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„ç´ æ
            recommended = self.recommend_for_script_section(section, limit=1)

            if not recommended and visual_notes:
                # æ²¡æœ‰åˆé€‚ç´ æï¼Œå»ºè®®æ·»åŠ 
                suggestions.append({
                    'section': section_name,
                    'visual_requirement': visual_notes,
                    'suggestion_type': 'missing',
                    'action': 'å»ºè®®ä½¿ç”¨AIç”Ÿæˆæˆ–æ‰‹åŠ¨æ·»åŠ ç´ æ'
                })

        return suggestions

    def analyze_material_coverage(
        self,
        script: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        åˆ†æç´ æåº“å¯¹è„šæœ¬çš„è¦†ç›–åº¦

        Args:
            script: è„šæœ¬æ•°æ®

        Returns:
            è¦†ç›–åº¦åˆ†æç»“æœ
        """
        total_sections = len(script.get('sections', []))
        covered_sections = 0
        partially_covered = 0

        coverage_details = []

        for section in script.get('sections', []):
            section_name = section.get('section_name', '')
            recommended = self.recommend_for_script_section(section, limit=3)

            if len(recommended) >= 3:
                covered_sections += 1
                status = 'full'
            elif len(recommended) > 0:
                partially_covered += 1
                status = 'partial'
            else:
                status = 'none'

            coverage_details.append({
                'section': section_name,
                'status': status,
                'available_materials': len(recommended)
            })

        coverage_rate = (covered_sections / total_sections * 100) if total_sections > 0 else 0

        return {
            'total_sections': total_sections,
            'fully_covered': covered_sections,
            'partially_covered': partially_covered,
            'not_covered': total_sections - covered_sections - partially_covered,
            'coverage_rate': round(coverage_rate, 2),
            'details': coverage_details
        }

    def _analyze_requirements(
        self,
        narration: str,
        visual_notes: str
    ) -> Dict[str, Any]:
        """
        åˆ†æç´ æéœ€æ±‚

        Args:
            narration: æ—ç™½æ–‡æœ¬
            visual_notes: è§†è§‰æç¤º

        Returns:
            éœ€æ±‚åˆ†æç»“æœ
        """
        # ä½¿ç”¨AIåˆ†æï¼ˆå¯é€‰ï¼Œä¹Ÿå¯ä»¥ç”¨ç®€å•çš„å…³é”®è¯æå–ï¼‰
        try:
            prompt = f"""
åˆ†æä»¥ä¸‹è§†é¢‘å†…å®¹éœ€è¦ä»€ä¹ˆç±»å‹çš„ç´ æï¼š

æ—ç™½: {narration[:200]}
è§†è§‰æç¤º: {visual_notes}

è¯·ä»¥JSONæ ¼å¼è¾“å‡º:
{{
  "material_types": ["image", "video", "animation"],
  "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
  "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"],
  "description": "ç´ æéœ€æ±‚æè¿°"
}}
"""
            result = self.ai_client.generate_json(prompt)
            return result

        except:
            # é™çº§åˆ°ç®€å•å…³é”®è¯æå–
            keywords = self._extract_keywords(narration + ' ' + visual_notes)
            return {
                'material_types': ['image'],
                'keywords': keywords,
                'tags': keywords,
                'description': visual_notes or narration[:100]
            }

    def _extract_keywords(self, text: str, max_keywords: int = 5) -> List[str]:
        """
        ç®€å•çš„å…³é”®è¯æå–

        Args:
            text: æ–‡æœ¬
            max_keywords: æœ€å¤§å…³é”®è¯æ•°

        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        # ç®€åŒ–å¤„ç†ï¼šæŒ‰ç©ºæ ¼åˆ†è¯ï¼Œè¿‡æ»¤å¸¸ç”¨è¯
        stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'}

        words = text.split()
        keywords = []

        for word in words:
            if len(word) >= 2 and word not in stop_words and word not in keywords:
                keywords.append(word)
                if len(keywords) >= max_keywords:
                    break

        return keywords

    def _deduplicate_and_score(
        self,
        materials: List[Dict[str, Any]],
        requirements: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        å»é‡å¹¶è¯„åˆ†æ’åº

        Args:
            materials: ç´ æåˆ—è¡¨
            requirements: éœ€æ±‚åˆ†æç»“æœ

        Returns:
            å»é‡æ’åºåçš„ç´ æåˆ—è¡¨
        """
        # å»é‡
        seen_ids = set()
        unique_materials = []

        for material in materials:
            mat_id = material.get('id')
            if mat_id not in seen_ids:
                seen_ids.add(mat_id)

                # è®¡ç®—åŒ¹é…åˆ†æ•°
                score = self._calculate_match_score(material, requirements)
                material['match_score'] = score

                unique_materials.append(material)

        # æŒ‰åŒ¹é…åˆ†æ•°æ’åº
        unique_materials.sort(key=lambda x: x.get('match_score', 0), reverse=True)

        return unique_materials

    def _calculate_match_score(
        self,
        material: Dict[str, Any],
        requirements: Dict[str, Any]
    ) -> float:
        """
        è®¡ç®—ç´ æä¸éœ€æ±‚çš„åŒ¹é…åˆ†æ•°

        Args:
            material: ç´ ææ•°æ®
            requirements: éœ€æ±‚æ•°æ®

        Returns:
            åŒ¹é…åˆ†æ•° (0-100)
        """
        score = 0.0

        # ç±»å‹åŒ¹é…
        required_types = requirements.get('material_types', [])
        if material.get('type') in required_types:
            score += 30

        # æ ‡ç­¾åŒ¹é…
        material_tags = set(material.get('tags', []))
        required_tags = set(requirements.get('tags', []))
        tag_overlap = len(material_tags & required_tags)
        if tag_overlap > 0:
            score += min(tag_overlap * 10, 30)

        # å…³é”®è¯åŒ¹é…
        material_text = (material.get('name', '') + ' ' +
                        material.get('description', '') + ' ' +
                        ' '.join(material.get('tags', []))).lower()

        keywords = requirements.get('keywords', [])
        keyword_matches = sum(1 for kw in keywords if kw.lower() in material_text)
        if keyword_matches > 0:
            score += min(keyword_matches * 10, 30)

        # è¯„åˆ†åŠ æˆ
        rating = material.get('rating')
        if rating:
            score += rating * 2

        # ä½¿ç”¨æ¬¡æ•°ï¼ˆé€‚åº¦åŠ æˆï¼Œé¿å…æ€»æ˜¯æ¨èç›¸åŒç´ æï¼‰
        used_count = material.get('used_count', 0)
        if used_count > 0:
            score += min(used_count, 10)

        # â­ V5.1: è§†é¢‘ç´ æä¼˜å…ˆ +50åˆ†
        if material.get('type') == 'video':
            score += 50

        return min(score, 100)

    # ===== V5.1 æ–°å¢: å¤–éƒ¨ç´ æè·å–æ–¹æ³• =====

    def _extract_english_keyword(self, narration: str, visual_notes: str) -> str:
        """
        æå–è‹±æ–‡å…³é”®è¯(ç”¨äºPexels/Unsplashæœç´¢)

        Args:
            narration: æ—ç™½æ–‡æœ¬
            visual_notes: è§†è§‰æç¤º

        Returns:
            è‹±æ–‡å…³é”®è¯
        """
        # ä¼˜å…ˆä½¿ç”¨visual_notes
        text = visual_notes if visual_notes else narration

        # ç®€å•æ˜ å°„(ä¸­æ–‡ â†’ è‹±æ–‡ç§‘æ™®å…³é”®è¯)
        keyword_map = {
            'å®‡å®™': 'space universe',
            'æ˜Ÿç©º': 'stars galaxy',
            'å¤ªç©º': 'space',
            'DNA': 'DNA genetics',
            'åŸºå› ': 'DNA genetics',
            'ç»†èƒ': 'cell biology',
            'å¤§è„‘': 'brain neuroscience',
            'ç¥ç»': 'neuron brain',
            'é‡å­': 'quantum physics',
            'ç‰©ç†': 'physics',
            'åŒ–å­¦': 'chemistry science',
            'ç”Ÿç‰©': 'biology nature',
            'ç§‘æŠ€': 'technology innovation',
            'äººå·¥æ™ºèƒ½': 'artificial intelligence AI',
            'AI': 'artificial intelligence',
            'æœºå™¨äºº': 'robot technology',
            'èƒ½æº': 'energy renewable',
            'ç¯å¢ƒ': 'environment nature',
            'æµ·æ´‹': 'ocean sea',
            'åœ°çƒ': 'earth planet',
            'ç«å±±': 'volcano',
            'åœ°éœ‡': 'earthquake',
            'æ°”å€™': 'climate weather',
            'åŒ»å­¦': 'medicine medical',
            'å¥åº·': 'health medical',
            'å¿ƒè„': 'heart cardiology',
            'è‚º': 'lungs respiratory',
            'è¡€æ¶²': 'blood circulation',
            'åˆ†å­': 'molecule chemistry',
            'åŸå­': 'atom physics',
            'ç”µå­': 'electron technology',
            'å…‰': 'light optics',
            'å£°éŸ³': 'sound wave',
            'ç”µ': 'electricity energy'
        }

        # æŸ¥æ‰¾åŒ¹é…
        for cn_keyword, en_keyword in keyword_map.items():
            if cn_keyword in text:
                return en_keyword

        # é»˜è®¤: é€šç”¨ç§‘æ™®å…³é”®è¯
        return 'science education'

    def _fetch_from_pexels_videos(self, keyword: str, count: int = 3) -> List[Dict[str, Any]]:
        """
        ä»Pexelsè·å–è§†é¢‘ç´ æ

        Args:
            keyword: è‹±æ–‡å…³é”®è¯
            count: æ•°é‡

        Returns:
            ç´ æä¿¡æ¯åˆ—è¡¨(å·²è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼)
        """
        if not self.pexels_fetcher:
            return []

        try:
            print(f"   ğŸ¥ [2/4] ä»Pexelsæœç´¢è§†é¢‘: '{keyword}'...")

            # æœç´¢
            videos = self.pexels_fetcher.search_videos(keyword, per_page=count)

            # è‡ªåŠ¨ä¸‹è½½
            materials = []
            for video in videos[:count]:
                if self.smart_fetch_config.get('auto_download', True):
                    filepath = self.pexels_fetcher.download_video(video, keyword)
                    if filepath:
                        # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
                        materials.append({
                            'id': f"pexels_video_{video['id']}",
                            'name': f"{keyword}_{video['id']}",
                            'type': 'video',
                            'file_path': filepath,
                            'tags': [keyword, 'pexels', 'HD'],
                            'description': f"Pexelsè§†é¢‘: {keyword}",
                            'source': 'pexels',
                            'match_score': 85,  # å¤–éƒ¨è§†é¢‘é»˜è®¤é«˜åˆ†
                            'rating': 4,
                            'used_count': 0
                        })

            return materials

        except Exception as e:
            print(f"       âŒ Pexelsè§†é¢‘è·å–å¤±è´¥: {str(e)}")
            return []

    def _fetch_from_pexels_photos(self, keyword: str, count: int = 3) -> List[Dict[str, Any]]:
        """ä»Pexelsè·å–å›¾ç‰‡ç´ æ"""
        if not self.pexels_fetcher:
            return []

        try:
            print(f"   ğŸ–¼ï¸  [3/4] ä»Pexelsæœç´¢å›¾ç‰‡: '{keyword}'...")

            photos = self.pexels_fetcher.search_photos(keyword, per_page=count)

            materials = []
            for photo in photos[:count]:
                if self.smart_fetch_config.get('auto_download', True):
                    filepath = self.pexels_fetcher.download_photo(photo, keyword)
                    if filepath:
                        materials.append({
                            'id': f"pexels_photo_{photo['id']}",
                            'name': f"{keyword}_{photo['id']}",
                            'type': 'image',
                            'file_path': filepath,
                            'tags': [keyword, 'pexels', 'HD'],
                            'description': f"Pexelså›¾ç‰‡: {keyword}",
                            'source': 'pexels',
                            'match_score': 75,
                            'rating': 4,
                            'used_count': 0
                        })

            return materials

        except Exception as e:
            print(f"       âŒ Pexelså›¾ç‰‡è·å–å¤±è´¥: {str(e)}")
            return []

    def _fetch_from_unsplash(self, keyword: str, count: int = 3) -> List[Dict[str, Any]]:
        """ä»Unsplashè·å–é«˜è´¨é‡å›¾ç‰‡"""
        if not self.unsplash_fetcher:
            return []

        try:
            print(f"   ğŸ“¸ [3/4] ä»Unsplashæœç´¢å›¾ç‰‡: '{keyword}'...")

            photos = self.unsplash_fetcher.search_photos(keyword, per_page=count)

            materials = []
            for photo in photos[:count]:
                if self.smart_fetch_config.get('auto_download', True):
                    filepath = self.unsplash_fetcher.download_photo(photo, keyword, quality='regular')
                    if filepath:
                        materials.append({
                            'id': f"unsplash_{photo['id']}",
                            'name': f"{keyword}_{photo['id']}",
                            'type': 'image',
                            'file_path': filepath,
                            'tags': [keyword, 'unsplash', 'HD'],
                            'description': photo.get('description', f"Unsplash: {keyword}"),
                            'source': 'unsplash',
                            'match_score': 80,
                            'rating': 5,  # Unsplashè´¨é‡æœ€é«˜
                            'used_count': 0
                        })

            return materials

        except Exception as e:
            print(f"       âŒ Unsplashè·å–å¤±è´¥: {str(e)}")
            return []
