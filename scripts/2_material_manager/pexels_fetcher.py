#!/usr/bin/env python3
"""
Pexelsè§†é¢‘å’Œå›¾ç‰‡ç´ æè·å–å™¨
æ”¯æŒè‡ªåŠ¨æœç´¢ã€ä¸‹è½½ã€ç¼“å­˜é«˜è´¨é‡å…è´¹ç´ æ
"""

import os
import json
import requests
from pathlib import Path
from typing import List, Dict, Optional, Any
import time
from datetime import datetime


class PexelsFetcher:
    """Pexelsç´ æè·å–å™¨ (è§†é¢‘+å›¾ç‰‡)"""

    def __init__(self, config_path: str = "config/settings.json"):
        """
        åˆå§‹åŒ–Pexelsè·å–å™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)

        # Pexels APIé…ç½®
        pexels_config = self.config.get("pexels", {})
        self.api_key = pexels_config.get("api_key") or os.getenv("PEXELS_API_KEY")

        if not self.api_key:
            print("âš ï¸  æœªé…ç½®Pexels APIå¯†é’¥")
            print("   è¯·è®¿é—® https://www.pexels.com/api/ å…è´¹ç”³è¯·")
            print("   ç„¶ååœ¨ config/settings.json ä¸­æ·»åŠ  pexels.api_key")

        # APIç«¯ç‚¹
        self.video_api_url = "https://api.pexels.com/videos/search"
        self.photo_api_url = "https://api.pexels.com/v1/search"

        # è¯·æ±‚å¤´
        self.headers = {
            "Authorization": self.api_key
        }

        # ç´ æä¿å­˜è·¯å¾„
        self.video_dir = Path(self.config["paths"]["materials"]) / "videos" / "pexels"
        self.image_dir = Path(self.config["paths"]["materials"]) / "images" / "pexels"
        self.video_dir.mkdir(parents=True, exist_ok=True)
        self.image_dir.mkdir(parents=True, exist_ok=True)

        # å…ƒæ•°æ®ç¼“å­˜
        self.cache_file = Path(self.config["paths"]["materials"]) / "pexels_cache.json"
        self.cache = self._load_cache()

    def _load_config(self, config_path: str) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âš ï¸  åŠ è½½é…ç½®å¤±è´¥: {str(e)}")
            return {"paths": {"materials": "./materials"}, "pexels": {}}

    def _load_cache(self) -> dict:
        """åŠ è½½å…ƒæ•°æ®ç¼“å­˜ï¼ˆV5.4ï¼šæ·»åŠ ä¸‹è½½è®°å½•ï¼‰"""
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    cache = json.load(f)
                    # ç¡®ä¿åŒ…å«ä¸‹è½½è®°å½•å­—æ®µ
                    if "downloaded_materials" not in cache:
                        cache["downloaded_materials"] = {}
                    return cache
            except:
                return {"videos": {}, "photos": {}, "downloaded_materials": {}}
        return {"videos": {}, "photos": {}, "downloaded_materials": {}}

    def _save_cache(self):
        """ä¿å­˜å…ƒæ•°æ®ç¼“å­˜"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜ç¼“å­˜å¤±è´¥: {str(e)}")

    def _record_download(self, material_id: str, local_path: str, material_type: str):
        """
        è®°å½•å·²ä¸‹è½½çš„ç´ æï¼ˆV5.4æ–°å¢ï¼‰

        Args:
            material_id: ç´ æIDï¼ˆæ ¼å¼ï¼špexels_video_123 æˆ– pexels_photo_456ï¼‰
            local_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            material_type: ç´ æç±»å‹ (video/photo)
        """
        self.cache["downloaded_materials"][material_id] = {
            "local_path": local_path,
            "type": material_type,
            "downloaded_at": time.time()
        }
        self._save_cache()

    def _check_downloaded(self, material_id: str) -> Optional[str]:
        """
        æ£€æŸ¥ç´ ææ˜¯å¦å·²ä¸‹è½½ï¼ˆV5.4æ–°å¢ï¼‰

        Args:
            material_id: ç´ æID

        Returns:
            æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœå·²ä¸‹è½½ä¸”æ–‡ä»¶å­˜åœ¨ï¼‰ï¼Œå¦åˆ™è¿”å›None
        """
        downloaded = self.cache.get("downloaded_materials", {}).get(material_id)
        if downloaded:
            local_path = downloaded.get("local_path")
            if local_path and os.path.exists(local_path):
                return local_path
        return None

    def search_videos(
        self,
        query: str,
        per_page: int = 5,
        orientation: str = "landscape",
        size: str = "medium"
    ) -> List[Dict[str, Any]]:
        """
        æœç´¢Pexelsè§†é¢‘

        Args:
            query: æœç´¢å…³é”®è¯ (è‹±æ–‡æ•ˆæœæœ€ä½³)
            per_page: æ¯é¡µç»“æœæ•° (æœ€å¤š15)
            orientation: æ–¹å‘ (landscape/portrait/square)
            size: å°ºå¯¸ (large/medium/small)

        Returns:
            è§†é¢‘ä¿¡æ¯åˆ—è¡¨
        """
        if not self.api_key:
            print("âŒ Pexels APIå¯†é’¥æœªé…ç½®")
            return []

        print(f"\nğŸ” æœç´¢Pexelsè§†é¢‘: '{query}'")

        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{query}_{orientation}_{size}"
        if cache_key in self.cache["videos"]:
            cached = self.cache["videos"][cache_key]
            # ç¼“å­˜æœ‰æ•ˆæœŸ7å¤©
            if time.time() - cached["timestamp"] < 7 * 86400:
                print(f"âœ… ä½¿ç”¨ç¼“å­˜ ({len(cached['results'])}ä¸ªç»“æœ)")
                return cached["results"]

        try:
            params = {
                "query": query,
                "per_page": min(per_page, 15),
                "orientation": orientation,
                "size": size
            }

            response = requests.get(
                self.video_api_url,
                headers=self.headers,
                params=params,
                timeout=10
            )

            if response.status_code == 200:
                data = response.json()
                videos = data.get("videos", [])

                # æå–å…³é”®ä¿¡æ¯
                results = []
                for video in videos:
                    video_files = video.get("video_files", [])

                    # ä¼˜å…ˆé€‰æ‹©1080p HDè§†é¢‘
                    hd_file = None
                    for vf in video_files:
                        if vf.get("quality") == "hd" and vf.get("width") == 1920:
                            hd_file = vf
                            break

                    # é™çº§åˆ°SD
                    if not hd_file and video_files:
                        hd_file = video_files[0]

                    if hd_file:
                        results.append({
                            "id": video["id"],
                            "url": hd_file["link"],
                            "width": video["width"],
                            "height": video["height"],
                            "duration": video.get("duration", 0),
                            "image": video.get("image"),
                            "user": video.get("user", {}).get("name", "Unknown"),
                            "quality": hd_file.get("quality", "sd")
                        })

                print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªè§†é¢‘")

                # æ›´æ–°ç¼“å­˜
                self.cache["videos"][cache_key] = {
                    "timestamp": time.time(),
                    "results": results
                }
                self._save_cache()

                return results

            elif response.status_code == 429:
                print("âš ï¸  APIè¯·æ±‚é™åˆ¶ (æ¯å°æ—¶200æ¬¡)")
                return []
            else:
                print(f"âŒ APIé”™è¯¯: {response.status_code}")
                return []

        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {str(e)}")
            return []

    def search_photos(
        self,
        query: str,
        per_page: int = 5,
        orientation: str = "landscape"
    ) -> List[Dict[str, Any]]:
        """
        æœç´¢Pexelså›¾ç‰‡

        Args:
            query: æœç´¢å…³é”®è¯
            per_page: æ¯é¡µç»“æœæ•° (æœ€å¤š80)
            orientation: æ–¹å‘

        Returns:
            å›¾ç‰‡ä¿¡æ¯åˆ—è¡¨
        """
        if not self.api_key:
            print("âŒ Pexels APIå¯†é’¥æœªé…ç½®")
            return []

        print(f"\nğŸ” æœç´¢Pexelså›¾ç‰‡: '{query}'")

        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{query}_{orientation}"
        if cache_key in self.cache["photos"]:
            cached = self.cache["photos"][cache_key]
            if time.time() - cached["timestamp"] < 7 * 86400:
                print(f"âœ… ä½¿ç”¨ç¼“å­˜ ({len(cached['results'])}ä¸ªç»“æœ)")
                return cached["results"]

        try:
            params = {
                "query": query,
                "per_page": min(per_page, 80),
                "orientation": orientation
            }

            response = requests.get(
                self.photo_api_url,
                headers=self.headers,
                params=params,
                timeout=10
            )

            if response.status_code == 200:
                data = response.json()
                photos = data.get("photos", [])

                results = []
                for photo in photos:
                    results.append({
                        "id": photo["id"],
                        "url": photo["src"]["large2x"],  # é«˜åˆ†è¾¨ç‡
                        "original_url": photo["src"]["original"],
                        "width": photo["width"],
                        "height": photo["height"],
                        "photographer": photo.get("photographer", "Unknown"),
                        "avg_color": photo.get("avg_color", "#000000")
                    })

                print(f"âœ… æ‰¾åˆ° {len(results)} å¼ å›¾ç‰‡")

                # æ›´æ–°ç¼“å­˜
                self.cache["photos"][cache_key] = {
                    "timestamp": time.time(),
                    "results": results
                }
                self._save_cache()

                return results
            else:
                print(f"âŒ APIé”™è¯¯: {response.status_code}")
                return []

        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {str(e)}")
            return []

    def download_video(
        self,
        video_info: Dict[str, Any],
        keyword: str = "video"
    ) -> Optional[str]:
        """
        ä¸‹è½½è§†é¢‘åˆ°æœ¬åœ°ï¼ˆV5.4ï¼šæ·»åŠ ä¸‹è½½è®°å½•ï¼‰

        Args:
            video_info: è§†é¢‘ä¿¡æ¯å­—å…¸
            keyword: å…³é”®è¯(ç”¨äºæ–‡ä»¶å‘½å)

        Returns:
            æœ¬åœ°æ–‡ä»¶è·¯å¾„æˆ–None
        """
        try:
            video_id = video_info["id"]
            url = video_info["url"]
            material_id = f"pexels_video_{video_id}"

            # V5.4: å…ˆæ£€æŸ¥ä¸‹è½½è®°å½•ç¼“å­˜
            cached_path = self._check_downloaded(material_id)
            if cached_path:
                print(f"   â­ï¸  å·²å­˜åœ¨ï¼ˆç¼“å­˜ï¼‰: {os.path.basename(cached_path)}")
                return cached_path

            # æ–‡ä»¶å: keyword_id.mp4
            safe_keyword = "".join(c for c in keyword if c.isalnum() or c in (' ', '-', '_')).strip()
            filename = f"{safe_keyword}_{video_id}.mp4"
            filepath = self.video_dir / filename

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if filepath.exists():
                print(f"   â­ï¸  å·²å­˜åœ¨: {filename}")
                # V5.4: è®°å½•åˆ°ç¼“å­˜ï¼ˆè¡¥å……é—æ¼çš„è®°å½•ï¼‰
                self._record_download(material_id, str(filepath), "video")
                return str(filepath)

            print(f"   â¬‡ï¸  ä¸‹è½½è§†é¢‘: {filename} ({video_info.get('quality', 'sd').upper()})")

            # ä¸‹è½½
            response = requests.get(url, stream=True, timeout=30)
            if response.status_code == 200:
                with open(filepath, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)

                file_size_mb = filepath.stat().st_size / (1024 * 1024)
                print(f"   âœ… ä¸‹è½½å®Œæˆ: {file_size_mb:.1f} MB")

                # V5.4: è®°å½•ä¸‹è½½
                self._record_download(material_id, str(filepath), "video")

                return str(filepath)
            else:
                print(f"   âŒ ä¸‹è½½å¤±è´¥: HTTP {response.status_code}")
                return None

        except Exception as e:
            print(f"   âŒ ä¸‹è½½é”™è¯¯: {str(e)}")
            return None

    def download_photo(
        self,
        photo_info: Dict[str, Any],
        keyword: str = "photo"
    ) -> Optional[str]:
        """
        ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°ï¼ˆV5.4ï¼šæ·»åŠ ä¸‹è½½è®°å½•ï¼‰

        Args:
            photo_info: å›¾ç‰‡ä¿¡æ¯å­—å…¸
            keyword: å…³é”®è¯

        Returns:
            æœ¬åœ°æ–‡ä»¶è·¯å¾„æˆ–None
        """
        try:
            photo_id = photo_info["id"]
            url = photo_info["url"]  # large2xç‰ˆæœ¬
            material_id = f"pexels_photo_{photo_id}"

            # V5.4: å…ˆæ£€æŸ¥ä¸‹è½½è®°å½•ç¼“å­˜
            cached_path = self._check_downloaded(material_id)
            if cached_path:
                print(f"   â­ï¸  å·²å­˜åœ¨ï¼ˆç¼“å­˜ï¼‰: {os.path.basename(cached_path)}")
                return cached_path

            safe_keyword = "".join(c for c in keyword if c.isalnum() or c in (' ', '-', '_')).strip()
            filename = f"{safe_keyword}_{photo_id}.jpg"
            filepath = self.image_dir / filename

            if filepath.exists():
                print(f"   â­ï¸  å·²å­˜åœ¨: {filename}")
                # V5.4: è®°å½•åˆ°ç¼“å­˜ï¼ˆè¡¥å……é—æ¼çš„è®°å½•ï¼‰
                self._record_download(material_id, str(filepath), "photo")
                return str(filepath)

            print(f"   â¬‡ï¸  ä¸‹è½½å›¾ç‰‡: {filename}")

            response = requests.get(url, timeout=15)
            if response.status_code == 200:
                with open(filepath, 'wb') as f:
                    f.write(response.content)

                file_size_kb = filepath.stat().st_size / 1024
                print(f"   âœ… ä¸‹è½½å®Œæˆ: {file_size_kb:.0f} KB")

                # V5.4: è®°å½•ä¸‹è½½
                self._record_download(material_id, str(filepath), "photo")

                return str(filepath)
            else:
                print(f"   âŒ ä¸‹è½½å¤±è´¥: HTTP {response.status_code}")
                return None

        except Exception as e:
            print(f"   âŒ ä¸‹è½½é”™è¯¯: {str(e)}")
            return None

    def fetch_and_download_videos(
        self,
        keyword: str,
        count: int = 5
    ) -> List[str]:
        """
        æœç´¢å¹¶ä¸‹è½½è§†é¢‘(ä¸€ç«™å¼)

        Args:
            keyword: å…³é”®è¯
            count: ä¸‹è½½æ•°é‡

        Returns:
            å·²ä¸‹è½½æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        videos = self.search_videos(keyword, per_page=count)

        downloaded = []
        for i, video in enumerate(videos[:count], 1):
            print(f"\nğŸ“¹ [{i}/{len(videos)}]")
            filepath = self.download_video(video, keyword)
            if filepath:
                downloaded.append(filepath)
            time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«

        return downloaded

    def fetch_and_download_photos(
        self,
        keyword: str,
        count: int = 5
    ) -> List[str]:
        """
        æœç´¢å¹¶ä¸‹è½½å›¾ç‰‡(ä¸€ç«™å¼)

        Args:
            keyword: å…³é”®è¯
            count: ä¸‹è½½æ•°é‡

        Returns:
            å·²ä¸‹è½½æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        photos = self.search_photos(keyword, per_page=count)

        downloaded = []
        for i, photo in enumerate(photos[:count], 1):
            print(f"\nğŸ–¼ï¸  [{i}/{len(photos)}]")
            filepath = self.download_photo(photo, keyword)
            if filepath:
                downloaded.append(filepath)
            time.sleep(0.3)

        return downloaded

    def get_stats(self) -> Dict[str, Any]:
        """
        è·å–ä¸‹è½½ç»Ÿè®¡

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        video_count = len(list(self.video_dir.glob("*.mp4")))
        photo_count = len(list(self.image_dir.glob("*.jpg"))) + len(list(self.image_dir.glob("*.png")))

        # è®¡ç®—æ€»å¤§å°
        video_size = sum(f.stat().st_size for f in self.video_dir.glob("*.mp4"))
        photo_size = sum(f.stat().st_size for f in self.image_dir.glob("*.jpg"))
        photo_size += sum(f.stat().st_size for f in self.image_dir.glob("*.png"))

        return {
            "video_count": video_count,
            "photo_count": photo_count,
            "total_count": video_count + photo_count,
            "video_size_mb": round(video_size / (1024 * 1024), 1),
            "photo_size_mb": round(photo_size / (1024 * 1024), 1),
            "total_size_mb": round((video_size + photo_size) / (1024 * 1024), 1)
        }


# å‘½ä»¤è¡Œæµ‹è¯•
if __name__ == "__main__":
    import sys

    fetcher = PexelsFetcher()

    if len(sys.argv) > 1:
        keyword = sys.argv[1]

        # æœç´¢å¹¶ä¸‹è½½è§†é¢‘
        print(f"\n{'='*60}")
        print(f"æœç´¢å…³é”®è¯: {keyword}")
        print(f"{'='*60}")

        videos = fetcher.fetch_and_download_videos(keyword, count=3)
        photos = fetcher.fetch_and_download_photos(keyword, count=3)

        print(f"\n{'='*60}")
        print(f"âœ… ä¸‹è½½å®Œæˆ!")
        print(f"   è§†é¢‘: {len(videos)} ä¸ª")
        print(f"   å›¾ç‰‡: {len(photos)} ä¸ª")
        print(f"{'='*60}")

        # æ˜¾ç¤ºç»Ÿè®¡
        stats = fetcher.get_stats()
        print(f"\nğŸ“Š ç´ æåº“ç»Ÿè®¡:")
        print(f"   æ€»è®¡: {stats['total_count']} ä¸ªç´ æ")
        print(f"   è§†é¢‘: {stats['video_count']} ä¸ª ({stats['video_size_mb']} MB)")
        print(f"   å›¾ç‰‡: {stats['photo_count']} ä¸ª ({stats['photo_size_mb']} MB)")
    else:
        print("ç”¨æ³•:")
        print("  python pexels_fetcher.py <å…³é”®è¯>")
        print("\nç¤ºä¾‹:")
        print("  python pexels_fetcher.py 'space'")
        print("  python pexels_fetcher.py 'DNA'")
        print("  python pexels_fetcher.py 'technology'")
