"""
ç´ æè¯­ä¹‰åˆ†æå™¨
ä½¿ç”¨GLM-4Vè§†è§‰æ¨¡å‹åˆ†æç´ æå†…å®¹ï¼Œç”Ÿæˆè¯¦ç»†åœºæ™¯æè¿°
V5.6æ–°å¢
"""

import json
import os
import sys
from typing import Dict, Any, Optional, List
import subprocess
import tempfile

# å¯¼å…¥AIå®¢æˆ·ç«¯
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '1_script_generator'))
from ai_client import AIClient


class SemanticAnalyzer:
    """ç´ æè¯­ä¹‰åˆ†æå™¨ - ä¸ºç´ æç”Ÿæˆè¯¦ç»†åœºæ™¯æè¿°"""

    def __init__(self, config_path: str = 'config/settings.json'):
        """
        åˆå§‹åŒ–è¯­ä¹‰åˆ†æå™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)

        # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
        self.ai_client = AIClient(self.config['ai'])

    def analyze_material(
        self,
        material: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        åˆ†æå•ä¸ªç´ æï¼Œç”Ÿæˆè¯­ä¹‰å…ƒæ•°æ®

        Args:
            material: ç´ ææ•°æ®

        Returns:
            è¯­ä¹‰å…ƒæ•°æ®å­—å…¸ï¼Œå¦‚æœåˆ†æå¤±è´¥è¿”å›None
        """
        file_path = material.get('file_path', '')
        material_type = material.get('type', '')

        if not file_path or not os.path.exists(file_path):
            print(f"   âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None

        try:
            if material_type == 'video':
                return self._analyze_video(file_path, material)
            elif material_type == 'image':
                return self._analyze_image(file_path, material)
            else:
                print(f"   âš ï¸  ä¸æ”¯æŒçš„ç±»å‹: {material_type}")
                return None

        except Exception as e:
            print(f"   âŒ åˆ†æå¤±è´¥: {str(e)}")
            return None

    def _analyze_video(
        self,
        video_path: str,
        material: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        åˆ†æè§†é¢‘ç´ æ

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            material: ç´ ææ•°æ®

        Returns:
            è¯­ä¹‰å…ƒæ•°æ®
        """
        # æå–å…³é”®å¸§
        keyframes = self._extract_keyframes(video_path, num_frames=3)

        if not keyframes:
            print(f"   âš ï¸  æ— æ³•æå–å…³é”®å¸§")
            return None

        # åˆ†æç¬¬ä¸€å¸§ï¼ˆä¸»è¦åœºæ™¯ï¼‰
        semantic_data = self._analyze_image_with_ai(keyframes[0], material)

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for frame in keyframes:
            try:
                os.remove(frame)
            except:
                pass

        return semantic_data

    def _analyze_image(
        self,
        image_path: str,
        material: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        åˆ†æå›¾ç‰‡ç´ æ

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            material: ç´ ææ•°æ®

        Returns:
            è¯­ä¹‰å…ƒæ•°æ®
        """
        return self._analyze_image_with_ai(image_path, material)

    def _analyze_image_with_ai(
        self,
        image_path: str,
        material: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        ä½¿ç”¨AIåˆ†æå›¾ç‰‡ï¼ˆGLM-4Vè§†è§‰æ¨¡å‹ï¼‰

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            material: ç´ ææ•°æ®

        Returns:
            è¯­ä¹‰å…ƒæ•°æ®
        """
        # æ£€æŸ¥æ˜¯å¦æ”¯æŒè§†è§‰æ¨¡å‹
        ai_config = self.config.get('ai', {})
        provider = ai_config.get('provider', 'openai')

        # å½“å‰åªæœ‰GLMæ”¯æŒè§†è§‰æ¨¡å‹ï¼Œå…¶ä»–é™çº§åˆ°æ–‡æœ¬åˆ†æ
        if provider != 'glm':
            print(f"   âš ï¸  å½“å‰AIæä¾›å•†({provider})ä¸æ”¯æŒè§†è§‰åˆ†æï¼Œä½¿ç”¨æ–‡æœ¬åˆ†æé™çº§")
            return self._fallback_text_analysis(material)

        # æ„å»ºåˆ†æprompt
        prompt = self._build_vision_prompt()

        try:
            # è°ƒç”¨GLM-4Vè§†è§‰æ¨¡å‹ï¼ˆéœ€è¦APIæ”¯æŒï¼‰
            # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾AIå®¢æˆ·ç«¯æ”¯æŒå›¾ç‰‡è¾“å…¥ï¼Œå®é™…éœ€è¦æ ¹æ®APIè°ƒæ•´
            result = self._call_vision_api(image_path, prompt)

            if result:
                return result
            else:
                # é™çº§åˆ°æ–‡æœ¬åˆ†æ
                return self._fallback_text_analysis(material)

        except Exception as e:
            print(f"   âš ï¸  è§†è§‰åˆ†æå¤±è´¥: {str(e)}ï¼Œä½¿ç”¨æ–‡æœ¬åˆ†æé™çº§")
            return self._fallback_text_analysis(material)

    def _call_vision_api(
        self,
        image_path: str,
        prompt: str
    ) -> Optional[Dict[str, Any]]:
        """
        è°ƒç”¨è§†è§‰APIï¼ˆGLM-4Vï¼‰

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            prompt: åˆ†æprompt

        Returns:
            åˆ†æç»“æœ
        """
        # TODO: è¿™é‡Œéœ€è¦æ ¹æ®GLM-4V APIå®é™…æ¥å£è°ƒæ•´
        # å½“å‰ç‰ˆæœ¬æš‚æ—¶ä¸å®ç°å›¾ç‰‡ä¸Šä¼ ï¼Œç›´æ¥é™çº§åˆ°æ–‡æœ¬åˆ†æ
        # æœªæ¥å¯ä»¥æ·»åŠ ï¼š
        # 1. è¯»å–å›¾ç‰‡å¹¶base64ç¼–ç 
        # 2. è°ƒç”¨GLM-4V vision API
        # 3. è§£æè¿”å›ç»“æœ

        return None

    def _fallback_text_analysis(
        self,
        material: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        é™çº§æ–‡æœ¬åˆ†æï¼ˆåŸºäºç´ æåç§°ã€æè¿°ã€æ ‡ç­¾ï¼‰

        Args:
            material: ç´ ææ•°æ®

        Returns:
            è¯­ä¹‰å…ƒæ•°æ®
        """
        # æå–æ–‡æœ¬ä¿¡æ¯
        name = material.get('name', '')
        description = material.get('description', '')
        tags = material.get('tags', [])

        # æ„å»ºåˆ†ææ–‡æœ¬
        text = f"ç´ æ: {name}\næè¿°: {description}\næ ‡ç­¾: {', '.join(tags)}"

        # æ„å»ºprompt
        prompt = f"""åˆ†æä»¥ä¸‹ç´ æçš„åœºæ™¯å†…å®¹ï¼Œç”Ÿæˆè¯¦ç»†çš„è¯­ä¹‰æè¿°ã€‚

{text}

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼š
{{
  "scene_description": "è¯¦ç»†çš„åœºæ™¯æè¿°ï¼ˆ50-100å­—ï¼‰",
  "main_objects": ["ä¸»è¦å¯¹è±¡1", "ä¸»è¦å¯¹è±¡2", "..."],
  "actions": ["åŠ¨ä½œ1", "åŠ¨ä½œ2", "..."],
  "visual_style": "è§†è§‰é£æ ¼æè¿°",
  "viewpoint": "è§†è§’/é•œå¤´ç±»å‹",
  "has_human": true/false,
  "complexity": "low/medium/high",
  "best_for_scenes": ["é€‚åˆçš„åœºæ™¯ç±»å‹1", "åœºæ™¯ç±»å‹2", "..."]
}}

åªè¿”å›JSONï¼Œæ— å…¶ä»–æ–‡å­—ã€‚"""

        try:
            result = self.ai_client.generate_json(prompt)
            return result
        except Exception as e:
            print(f"   âš ï¸  æ–‡æœ¬åˆ†æå¤±è´¥: {str(e)}")
            # è¿”å›åŸºç¡€å…ƒæ•°æ®
            return self._create_basic_metadata(material)

    def _create_basic_metadata(
        self,
        material: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        åˆ›å»ºåŸºç¡€è¯­ä¹‰å…ƒæ•°æ®ï¼ˆæœ€ä½é™çº§æ–¹æ¡ˆï¼‰

        Args:
            material: ç´ ææ•°æ®

        Returns:
            åŸºç¡€å…ƒæ•°æ®
        """
        description = material.get('description', '')
        tags = material.get('tags', [])

        return {
            'scene_description': description or f"ç´ æ: {material.get('name', '')}",
            'main_objects': tags[:3] if tags else [],
            'actions': [],
            'visual_style': material.get('type', 'unknown'),
            'viewpoint': 'unknown',
            'has_human': False,
            'complexity': 'medium',
            'best_for_scenes': tags[:2] if tags else []
        }

    def _extract_keyframes(
        self,
        video_path: str,
        num_frames: int = 3
    ) -> List[str]:
        """
        ä»è§†é¢‘æå–å…³é”®å¸§

        Args:
            video_path: è§†é¢‘è·¯å¾„
            num_frames: æå–å¸§æ•°

        Returns:
            å…³é”®å¸§æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        keyframes = []

        try:
            # è·å–è§†é¢‘æ—¶é•¿
            duration_cmd = [
                'ffprobe',
                '-v', 'error',
                '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                video_path
            ]

            result = subprocess.run(
                duration_cmd,
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode != 0:
                return []

            duration = float(result.stdout.strip())

            # è®¡ç®—æå–æ—¶é—´ç‚¹ï¼ˆå‡åŒ€åˆ†å¸ƒï¼‰
            timestamps = [duration * i / (num_frames + 1) for i in range(1, num_frames + 1)]

            # æå–å…³é”®å¸§
            for i, timestamp in enumerate(timestamps):
                temp_file = os.path.join(
                    tempfile.gettempdir(),
                    f"keyframe_{os.getpid()}_{i}.jpg"
                )

                extract_cmd = [
                    'ffmpeg',
                    '-ss', str(timestamp),
                    '-i', video_path,
                    '-vframes', '1',
                    '-y',
                    temp_file
                ]

                result = subprocess.run(
                    extract_cmd,
                    capture_output=True,
                    timeout=10
                )

                if result.returncode == 0 and os.path.exists(temp_file):
                    keyframes.append(temp_file)

        except Exception as e:
            print(f"   âš ï¸  æå–å…³é”®å¸§å¤±è´¥: {str(e)}")

        return keyframes

    def _build_vision_prompt(self) -> str:
        """
        æ„å»ºè§†è§‰åˆ†æprompt

        Returns:
            promptæ–‡æœ¬
        """
        return """åˆ†æè¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼Œç”¨äºç§‘æ™®è§†é¢‘ç´ æåŒ¹é…ã€‚

è¯·è¯¦ç»†æè¿°ï¼š
1. ä¸»è¦è§†è§‰å¯¹è±¡ï¼ˆå…·ä½“ç‰©ä½“ã€äººç‰©ã€åœºæ™¯ï¼‰
2. åŠ¨ä½œæˆ–çŠ¶æ€ï¼ˆé™æ€/åŠ¨æ€ï¼Œå‘ç”Ÿäº†ä»€ä¹ˆï¼‰
3. è§†è§‰é£æ ¼ï¼ˆCGåŠ¨ç”»/å®æ‹/æ’ç”»/å›¾è¡¨ç­‰ï¼‰
4. é•œå¤´è§†è§’ï¼ˆç‰¹å†™/å…¨æ™¯/ä¿¯è§†ç­‰ï¼‰
5. æ˜¯å¦æœ‰äººç‰©å‡ºç°
6. é€‚åˆå“ªäº›ç§‘æ™®åœºæ™¯

ä»¥JSONæ ¼å¼è¾“å‡ºï¼š
{
  "scene_description": "è¯¦ç»†åœºæ™¯æè¿°ï¼ˆ50-100å­—ï¼‰",
  "main_objects": ["å¯¹è±¡1", "å¯¹è±¡2"],
  "actions": ["åŠ¨ä½œ1", "åŠ¨ä½œ2"],
  "visual_style": "è§†è§‰é£æ ¼",
  "viewpoint": "è§†è§’ç±»å‹",
  "has_human": true/false,
  "complexity": "low/medium/high",
  "best_for_scenes": ["åœºæ™¯1", "åœºæ™¯2"]
}

åªè¿”å›JSONï¼Œæ— å…¶ä»–å†…å®¹ã€‚"""


def auto_analyze_new_material(
    material: Dict[str, Any],
    config_path: str = 'config/settings.json'
) -> Dict[str, Any]:
    """
    è‡ªåŠ¨åˆ†ææ–°ç´ æå¹¶æ·»åŠ è¯­ä¹‰å…ƒæ•°æ®ï¼ˆå·¥å…·å‡½æ•°ï¼‰

    Args:
        material: æ–°æ·»åŠ çš„ç´ ææ•°æ®
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„

    Returns:
        æ·»åŠ äº†semantic_metadataçš„ç´ ææ•°æ®
    """
    analyzer = SemanticAnalyzer(config_path)

    print(f"   ğŸ” æ­£åœ¨åˆ†æç´ æ: {material.get('name', 'N/A')}...")

    semantic_metadata = analyzer.analyze_material(material)

    if semantic_metadata:
        material['semantic_metadata'] = semantic_metadata
        print(f"   âœ… è¯­ä¹‰åˆ†æå®Œæˆ")
        print(f"      åœºæ™¯: {semantic_metadata.get('scene_description', 'N/A')[:60]}...")
    else:
        print(f"   âš ï¸  è¯­ä¹‰åˆ†æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€å…ƒæ•°æ®")
        material['semantic_metadata'] = analyzer._create_basic_metadata(material)

    return material
